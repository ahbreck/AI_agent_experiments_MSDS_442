{
 "cells": [
  {
   "cell_type": "raw",
   "id": "023635f2-71cf-43f2-a2e2-a7b4ced30a74",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc5bb2-017f-434e-8cd6-53ab214a5604",
   "metadata": {},
   "source": [
    "# Build a Retrieval Augmented Generation (RAG) App: Part 2\n",
    "\n",
    "In many Q&A applications we want to allow the user to have a back-and-forth conversation, meaning the application needs some sort of \"memory\" of past questions and answers, and some logic for incorporating those into its current thinking.\n",
    "\n",
    "This is a the second part of a multi-part tutorial:\n",
    "\n",
    "- [Part 1](/docs/tutorials/rag) introduces RAG and walks through a minimal implementation.\n",
    "- [Part 2](/docs/tutorials/qa_chat_history) (this guide) extends the implementation to accommodate conversation-style interactions and multi-step retrieval processes.\n",
    "\n",
    "Here we focus on **adding logic for incorporating historical messages.** This involves the management of a [chat history](/docs/concepts/chat_history).\n",
    "\n",
    "We will cover two approaches:\n",
    "\n",
    "1. [Chains](/docs/tutorials/qa_chat_history/#chains), in which we execute at most one retrieval step;\n",
    "2. [Agents](/docs/tutorials/qa_chat_history/#agents), in which we give an LLM discretion to execute multiple retrieval steps.\n",
    "\n",
    ":::note\n",
    "\n",
    "The methods presented here leverage [tool-calling](/docs/concepts/tool_calling/) capabilities in modern [chat models](/docs/concepts/chat_models). See [this page](/docs/integrations/chat/) for a table of models supporting tool calling features.\n",
    "\n",
    ":::\n",
    "\n",
    "For the external knowledge source, we will use the same [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) blog post by Lilian Weng from the [Part 1](/docs/tutorials/rag) of the RAG tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d8d79-5ee9-4aa4-9fdf-cd5f4303e099",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Components\n",
    "\n",
    "We will need to select three components from LangChain's suite of integrations.\n",
    "\n",
    "A [chat model](/docs/integrations/chat/):\n",
    "\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc41951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_PROJECT: MSDS_442_labs\n",
      "LANGCHAIN_TRACING_V2: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(override=True)\n",
    "\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\") == \"true\"\n",
    "\n",
    "print(\"LANGCHAIN_PROJECT:\", LANGCHAIN_PROJECT)\n",
    "print(\"LANGCHAIN_TRACING_V2:\", LANGCHAIN_TRACING_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab0dd56-7437-4aeb-af20-7f420d47ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14773e-ac98-4a97-944b-4c6ec028d195",
   "metadata": {},
   "source": [
    "An [embedding model](/docs/integrations/text_embedding/):\n",
    "\n",
    "import EmbeddingTabs from \"@theme/EmbeddingTabs\";\n",
    "\n",
    "<EmbeddingTabs/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4691bd31-d8f4-4ba1-aec5-44935400f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fdc314-b91d-4820-b0a8-873b5b6e76f5",
   "metadata": {},
   "source": [
    "And a [vector store](/docs/integrations/vectorstores/):\n",
    "\n",
    "import VectorStoreTabs from \"@theme/VectorStoreTabs\";\n",
    "\n",
    "<VectorStoreTabs/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137d3848-7265-4673-9779-4c5f604da469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc335b-dc8a-4c40-aece-3aa9057cc6bd",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "In addition, we'll use the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede7fdc0-ef31-483d-bd67-32e4b5c5d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langgraph langchain-community beautifulsoup4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e207ac1d-4a8e-4172-a9ee-3294519a9a40",
   "metadata": {},
   "source": [
    "### LangSmith\n",
    "\n",
    "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with [LangSmith](https://smith.langchain.com).\n",
    "\n",
    "Note that LangSmith is not needed, but it is helpful. If you do want to use LangSmith, after you sign up at the link above, make sure to set your environment variables to start logging traces:\n",
    "\n",
    "```python\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "if not os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ba684-26cf-4860-904e-a4d51380c134",
   "metadata": {},
   "source": [
    "## Chains {#chains}\n",
    "\n",
    "Let's first revisit the vector store we built in [Part 1](/docs/tutorials/rag), which indexes an [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) blog post by Lilian Weng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe06d69-33c9-4ca3-98fb-8c70cde9dba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_classic import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4369949-39f1-4cdc-b652-179e0b891b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c26d5f-1493-4ad6-9210-ea2723695149",
   "metadata": {},
   "source": [
    "In the [Part 1](/docs/tutorials/rag) of the RAG tutorial, we represented the user input, retrieved context, and generated answer as separate keys in the state. Conversational experiences can be naturally represented using a sequence of [messages](/docs/concepts/messages/). In addition to messages from the user and assistant, retrieved documents and other artifacts can be incorporated into a message sequence via [tool messages](/docs/concepts/messages/#toolmessage). This motivates us to represent the state of our RAG application using a sequence of messages. Specifically, we will have\n",
    "\n",
    "1. User input as a `HumanMessage`;\n",
    "2. Vector store query as an `AIMessage` with tool calls;\n",
    "3. Retrieved documents as a `ToolMessage`;\n",
    "4. Final response as a `AIMessage`.\n",
    "\n",
    "This model for state is so versatile that LangGraph offers a built-in version for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27d97f0-27dc-438b-bf61-a403ca284522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eeb6a1-29f2-4086-8b6f-8761cf24ce59",
   "metadata": {},
   "source": [
    "Leveraging [tool-calling](/docs/concepts/tool_calling/) to interact with a retrieval step has another benefit, which is that the query for the retrieval is generated by our model. This is especially important in a conversational setting, where user queries may require contextualization based on the chat history. For instance, consider the following exchange:\n",
    "\n",
    "> Human: \"What is Task Decomposition?\"\n",
    ">\n",
    "> AI: \"Task decomposition involves breaking down complex tasks into smaller and simpler steps to make them more manageable for an agent or model.\"\n",
    ">\n",
    "> Human: \"What are common ways of doing it?\"\n",
    "\n",
    "In this scenario, a model could generate a query such as `\"common approaches to task decomposition\"`. Tool-calling facilitates this naturally. As in the [query analysis](/docs/tutorials/rag#query-analysis) section of the RAG tutorial, this allows a model to rewrite user queries into more effective search queries. It also provides support for direct responses that do not involve a retrieval step (e.g., in response to a generic greeting from the user).\n",
    "\n",
    "Let's turn our retrieval step into a [tool](/docs/concepts/tools):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8201a6ef-942f-4571-b3b9-55a430590266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03f752-d46d-4070-b790-197b742c4dc2",
   "metadata": {},
   "source": [
    "See [this guide](/docs/how_to/custom_tools/) for more detail on creating tools.\n",
    "\n",
    "Our graph will consist of three nodes:\n",
    "\n",
    "1. A node that fields the user input, either generating a query for the retriever or responding directly;\n",
    "2. A node for the retriever tool that executes the retrieval step;\n",
    "3. A node that generates the final response using the retrieved context.\n",
    "\n",
    "We build them below. Note that we leverage another pre-built LangGraph component, [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode), that executes the tool and adds the result as a `ToolMessage` to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0ce8c9-b404-424b-886e-c1386368ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409ee5f-2973-47ee-a1bf-112731843c5d",
   "metadata": {},
   "source": [
    "Finally, we compile our application into a single `graph` object. In this case, we are just connecting the steps into a sequence. We also allow the first `query_or_respond` step to \"short-circuit\" and respond directly to the user if it does not generate a tool call. This allows our application to support conversational experiences-- e.g., responding to generic greetings that may not require a retrieval step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac33f19c-7959-4526-8f12-0de76ae10387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7e1717-d262-4947-a64d-6b116e53856a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b6209-ee06-42ba-b266-d90d9cbf224b",
   "metadata": {},
   "source": [
    "Let's test our application.\n",
    "\n",
    "Note that it responds appropriately to messages that do not require an additional retrieval step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fbca953-970d-4271-be30-6c7799893dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5046d-4610-4ffa-9f30-d04453da05a9",
   "metadata": {},
   "source": [
    "And when executing a search, we can stream the steps to observe the query generation, retrieval, and answer generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ab78984-d7fa-40e1-a440-c041a6456c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_M91pt3XbFcKE4uuL4HS0GWLe)\n",
      " Call ID: call_M91pt3XbFcKE4uuL4HS0GWLe\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task Decomposition is the process of breaking down a complicated task into smaller, manageable steps. Techniques like Chain of Thought (CoT) and Tree of Thoughts extend this concept by facilitating step-by-step reasoning or exploring multiple reasoning pathways. This approach aids in enhancing model performance and understanding the thought process during complex tasks.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a9c4d-0e5b-4db9-8b78-68624d829ac2",
   "metadata": {},
   "source": [
    "Check out the LangSmith trace [here](https://smith.langchain.com/public/70110399-01d3-4b4b-9139-cbcd4edf9d6d/r)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2300c04-019c-4c65-a104-3dbf17c924b7",
   "metadata": {},
   "source": [
    "### Stateful management of chat history\n",
    "\n",
    ":::note\n",
    "\n",
    "This section of the tutorial previously used the [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) abstraction. You can access that version of the documentation in the [v0.2 docs](https://python.langchain.com/v0.2/docs/tutorials/chatbot/).\n",
    "\n",
    "As of the v0.3 release of LangChain, we recommend that LangChain users take advantage of [LangGraph persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) to incorporate `memory` into new LangChain applications.\n",
    "\n",
    "If your code is already relying on `RunnableWithMessageHistory` or `BaseChatMessageHistory`, you do **not** need to make any changes. We do not plan on deprecating this functionality in the near future as it works for simple chat applications and any code that uses `RunnableWithMessageHistory` will continue to work as expected.\n",
    "\n",
    "Please see [How to migrate to LangGraph Memory](/docs/versions/migrating_memory/) for more details.\n",
    ":::\n",
    "\n",
    "In production, the Q&A application will usually persist the chat history into a database, and be able to read and update it appropriately.\n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/) implements a built-in [persistence layer](https://langchain-ai.github.io/langgraph/concepts/persistence/), making it ideal for chat applications that support multiple conversational turns.\n",
    "\n",
    "To manage multiple conversational turns and threads, all we have to do is specify a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/) when compiling our application. Because the nodes in our graph are appending messages to the state, we will retain a consistent chat history across invocations.\n",
    "\n",
    "LangGraph comes with a simple in-memory checkpointer, which we use below. See its [documentation](https://langchain-ai.github.io/langgraph/concepts/persistence/) for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\n",
    "\n",
    "For a detailed walkthrough of how to manage message history, head to the [How to add message history (memory)](/docs/how_to/message_history) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5cd784a-61b2-4f9c-ad92-3e555b33d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557b169-b33c-42d0-b97e-1b948d0a2914",
   "metadata": {},
   "source": [
    "We can now invoke similar to before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6d16477-52f5-4755-83d1-60eebddfaaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_MtzmawlgUih89CANaxlgA4gq)\n",
      " Call ID: call_MtzmawlgUih89CANaxlgA4gq\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a complicated task into smaller, more manageable steps. This can be achieved through various techniques, such as prompting large language models (LLMs) to think step by step, using task-specific instructions, or incorporating human inputs. It enhances performance on complex tasks by making them easier to understand and handle.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9d6f0ee-b5a9-4141-9f6f-ad86a04e083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up some common ways of doing it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_PsHjtbhTTxg34JqDrLd6ZIZR)\n",
      " Call ID: call_PsHjtbhTTxg34JqDrLd6ZIZR\n",
      "  Args:\n",
      "    query: common methods for task decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Common ways of performing task decomposition include: \n",
      "\n",
      "1. Using simple prompting techniques like asking for the steps or subgoals for achieving a task.\n",
      "2. Applying task-specific instructions, such as requesting a story outline for writing a novel.\n",
      "3. Integrating human inputs to guide the decomposition process. \n",
      "\n",
      "Additionally, external classical planners may be utilized in some setups to handle long-horizon planning with structured language.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Can you look up some common ways of doing it?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbeef2-d9a1-4857-874f-9f3b5cc4eca9",
   "metadata": {},
   "source": [
    "Note that the query generated by the model in the second question incorporates the conversational context.\n",
    "\n",
    "The [LangSmith](https://smith.langchain.com/public/28e6179f-fc56-45e1-9028-447d76352c14/r) trace is particularly informative here, as we can see exactly what messages are visible to our chat model at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0",
   "metadata": {},
   "source": [
    "## Agents {#agents}\n",
    "\n",
    "[Agents](/docs/concepts/agents) leverage the reasoning capabilities of LLMs to make decisions during execution. Using agents allows you to offload additional discretion over the retrieval process. Although their behavior is less predictable than the above \"chain\", they are able to execute multiple retrieval steps in service of a query, or iterate on a single search.\n",
    "\n",
    "Below we assemble a minimal RAG agent. Using LangGraph's [pre-built ReAct agent constructor](https://langchain-ai.github.io/langgraph/how-tos/#langgraph.prebuilt.chat_agent_executor.create_react_agent), we can do this in one line.\n",
    "\n",
    ":::tip\n",
    "\n",
    "Check out LangGraph's [Agentic RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/) tutorial for more advanced formulations.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "470d5996-527d-4ef1-9e31-2c259cc3c050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahbre\\AppData\\Local\\Temp\\ipykernel_5356\\653244713.py:3: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8f8734-5dcf-4058-a532-11c8a7d0efae",
   "metadata": {},
   "source": [
    "Let's inspect the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0907cef3-05cb-45c7-ab46-382c58c52eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98",
   "metadata": {},
   "source": [
    "The key difference from our earlier implementation is that instead of a final generation step that ends the run, here the tool invocation loops back to the original LLM call. The model can then either answer the question using the retrieved context, or generate another tool call to obtain more information.\n",
    "\n",
    "Let's test this out. We construct a question that would typically require an iterative sequence of retrieval steps to answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2f48f92-bd91-4033-a01b-7bd0667e3d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_K8VS6iLME2YaDmEb0npzGSzA)\n",
      " Call ID: call_K8VS6iLME2YaDmEb0npzGSzA\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_g3D98fZb7TvUrf2z7p6erLid)\n",
      " Call ID: call_g3D98fZb7TvUrf2z7p6erLid\n",
      "  Args:\n",
      "    query: common extensions of Task Decomposition methods\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Standard Method for Task Decomposition\n",
      "The standard method for task decomposition involves breaking down a complicated task into smaller, manageable steps. This can be done using various techniques, such as:\n",
      "\n",
      "1. **Chain of Thought (CoT)**: A prompting technique that encourages a model to \"think step by step\" to simplify complex tasks into smaller tasks, improving understanding and interpretability of the decision-making process.\n",
      "\n",
      "2. **Different Approaches**:\n",
      "   - **Simple Prompting**: Asking for steps or subgoals directly, e.g., \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\n",
      "   - **Task-Specific Instructions**: Providing specific commands tailored to the task, such as \"Write a story outline\" for creative tasks.\n",
      "   - **Human Inputs**: Relying on human expertise to guide the decomposition process.\n",
      "\n",
      "3. **LLM+P Method**: Using an external classical planner to manage long-horizon planning by translating problems into Planning Domain Definition Language (PDDL) and utilizing classical planning tools to generate structured plans.\n",
      "\n",
      "### Common Extensions of Task Decomposition\n",
      "Several extensions have emerged to enhance the standard task decomposition techniques:\n",
      "\n",
      "1. **Tree of Thoughts**: This method extends the CoT by exploring multiple reasoning possibilities at each step. It creates a tree structure where multiple thoughts are generated for each thought step. The search for solutions can employ Breadth-First Search (BFS) or Depth-First Search (DFS), evaluating each state through classification or majority voting.\n",
      "\n",
      "2. **Integration of Classical Planning Tools**: The LLM+P approach, as mentioned above, leverages external planners to generate plans, which is especially useful in scenarios requiring domain-specific knowledge or sophisticated problem-solving capabilities.\n",
      "\n",
      "These methodologies build upon the foundation of breaking tasks into manageable parts, enhancing the flexibility and effectiveness of task decomposition strategies.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab58d2-92ef-4940-a535-7c8808e75523",
   "metadata": {},
   "source": [
    "Note that the agent:\n",
    "\n",
    "1. Generates a query to search for a standard method for task decomposition;\n",
    "2. Receiving the answer, generates a second query to search for common extensions of it;\n",
    "3. Having received all necessary context, answers the question.\n",
    "\n",
    "We can see the full sequence of steps, along with latency and other metadata, in the [LangSmith trace](https://smith.langchain.com/public/48cbd35e-9ac1-49ab-8c09-500d54c06b81/r).\n",
    "\n",
    "## Next steps\n",
    "\n",
    "We've covered the steps to build a basic conversational Q&A application:\n",
    "\n",
    "- We used chains to build a predictable application that generates at most one query per user input;\n",
    "- We used agents to build an application that can iterate on a sequence of queries.\n",
    "\n",
    "To explore different types of retrievers and retrieval strategies, visit the [retrievers](/docs/how_to/#retrievers) section of the how-to guides.\n",
    "\n",
    "For a detailed walkthrough of LangChain's conversation memory abstractions, visit the [How to add message history (memory)](/docs/how_to/message_history) guide.\n",
    "\n",
    "To learn more about agents, check out the [conceptual guide](/docs/concepts/agents) and LangGraph [agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97b7c675-4011-43d2-9a6a-ddcf75fec536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the difference between Chain of Thought and Tree of Thoughts ?\n",
      "\n",
      "Once you get the answer, which one is preferred to review and analyze financial reports \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_eOhKMVpvGrCcXoPDkctOWrW3)\n",
      " Call ID: call_eOhKMVpvGrCcXoPDkctOWrW3\n",
      "  Args:\n",
      "    query: difference between Chain of Thought and Tree of Thoughts\n",
      "  retrieve (call_Ck8hqozxjzmogc1LbESiGQvx)\n",
      " Call ID: call_Ck8hqozxjzmogc1LbESiGQvx\n",
      "  Args:\n",
      "    query: which is preferred for reviewing and analyzing financial reports: Chain of Thought or Tree of Thoughts\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\n",
      "\n",
      "\n",
      "Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Difference Between Chain of Thought (CoT) and Tree of Thoughts (ToT)\n",
      "\n",
      "1. **Chain of Thought (CoT)**:\n",
      "   - CoT is a prompting technique that emphasizes step-by-step reasoning.\n",
      "   - It decomposes complex tasks into smaller, manageable tasks, allowing the model to think through problems systematically.\n",
      "   - The approach enhances model performance on intricate tasks by illuminating the model's thought process.\n",
      "\n",
      "2. **Tree of Thoughts (ToT)**:\n",
      "   - ToT builds on the CoT framework by exploring multiple reasoning pathways at each step.\n",
      "   - It decomposes a problem into various thought steps, generating multiple thoughts for each step and forming a tree-like structure.\n",
      "   - The exploration can be done using breadth-first search (BFS) or depth-first search (DFS), with each state evaluated through a classifier or a voting system.\n",
      "\n",
      "### Preference for Reviewing and Analyzing Financial Reports\n",
      "\n",
      "For reviewing and analyzing financial reports, **Tree of Thoughts (ToT)** is preferred. This is due to its capability to discover and evaluate multiple possible paths for reasoning, providing a more comprehensive analysis of complex financial data. The structured exploration allows for a thorough understanding of the nuances within financial reports, enabling better decision-making.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"ghi567\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the difference between Chain of Thought and Tree of Thoughts ?\\n\\n\"\n",
    "    \"Once you get the answer, which one is preferred to review and analyze financial reports \"\n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds_442",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
