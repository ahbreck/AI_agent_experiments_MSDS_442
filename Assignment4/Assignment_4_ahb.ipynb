{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<hr style=\"border:30px solid Firebrick \"> </hr>\n",
    "<hr style=\"border:2px solid Firebrick \"> </hr>\n",
    "\n",
    "# Agentic Workflow Automation for Northwestern Memorial Hospital\n",
    "**Author:** Atef Bader, PhD\n",
    "\n",
    "**Last Edit:** 12/17/2024\n",
    "\n",
    "\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Automate Call/Inquiry processing using Langgraph/Langchain with OpenAI\n",
    "- Use OpenAI to route and answer user's questions directed to different departments represented by different agents for Northwestern Memorial Hospital\n",
    "\n",
    "<hr style=\"border:2px solid Firebrick \"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"attachment:6925f10a-1fae-4385-a348-d427e8a93cf0.png\" align=\"center\" width=\"500\"/>\n",
    "\n",
    "\n",
    "<hr style=\"border:5px solid orange \"> </hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%%capture --no-stderr\n",
    "%pip install uv\n",
    "%uv pip install chromadb==0.4.22\n",
    "%uv pip install tiktoken==0.9.0\n",
    "%uv pip install langchain==0.3.20\n",
    "%uv pip install langchain-community==0.3.10\n",
    "%uv pip install langchain-openai==0.3.1\n",
    "%uv pip install langchainhub\n",
    "%uv pip install langchain-text-splitters==0.3.6\n",
    "%uv pip install langgraph==0.3.1\n",
    "%uv pip install openai==1.65.3\n",
    "%uv pip install PyMuPDF==1.25.3\n",
    "%uv pip install pypdf==5.3.1\n",
    "%uv pip install pillow==11.1.0\n",
    "%uv pip install beautifulsoup4==4.13.3\n",
    "%uv pip install  mermaid_cli\n",
    "%uv pip install grandalf'''\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from typing import TypedDict, Optional, List, Dict, Any, Annotated, Tuple, Optional, Literal\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "### NEW\n",
    "import shutil\n",
    "from langchain.agents import create_agent\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "from __future__ import annotations\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import csv\n",
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\") == \"true\"\n",
    "\n",
    "INPUT_DIR = Path.cwd() / \"Input\"\n",
    "OUTPUT_DIR = Path.cwd() / \"Output\"\n",
    "\n",
    "KB_DIR = Path.cwd() / \"kb\"\n",
    "CARDIOLOGY_SCHEDULE_CSV = KB_DIR / \"cardiology_appointment_slots.csv\"\n",
    "CARDIOLOGY_KB_PATH = \"./kb/cardiology_kb.jsonl\"\n",
    "\n",
    "REBUILD_CHROMA = False   # <-- set to False to reuse persisted DB\n",
    "#CHROMA_DIR = \"./chroma_kb\"\n",
    "CHROMA_DIR = \"./chroma_kb_rebuild\" if REBUILD_CHROMA else \"./chroma_kb\"\n",
    "\n",
    "\n",
    "print(\"LANGCHAIN_PROJECT:\", LANGCHAIN_PROJECT)\n",
    "print(\"LANGCHAIN_TRACING_V2:\", LANGCHAIN_TRACING_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Declare state dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 1: Define the structure of agent state for the LangGraph\n",
    "class InquiryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    inquiry: str\n",
    "    next_node: str\n",
    "    response: Optional[str]\n",
    "\n",
    "    # routing\n",
    "    intent: Optional[str]\n",
    "    active_agent: Optional[str]  # which agent currently owns the thread\n",
    "    last_router_reason: Optional[str]\n",
    "\n",
    "    # retrieval payload\n",
    "    retrieved: Optional[List[Dict[str, Any]]]  # JSON-serializable so easy to log/debug. [{id, text, score, meta}, ...]\n",
    "    retrieval_confidence: Optional[float]\n",
    "\n",
    "\n",
    "ROUTABLE_AGENTS = {\n",
    "    \"ER\",\n",
    "    \"Radiology\",\n",
    "    \"PrimaryCare\",\n",
    "    \"Cardiology\",\n",
    "    \"Pediatrics\",\n",
    "    \"BillingInsurance\",\n",
    "}\n",
    "\n",
    "INTENT_MAP = {\n",
    "    \"greeting\": \"Greeting\",\n",
    "    \"generalinquiry\": \"GeneralInquiry\",\n",
    "    \"er\": \"ER\",\n",
    "    \"radiology\": \"Radiology\",\n",
    "    \"primarycare\": \"PrimaryCare\",\n",
    "    \"cardiology\": \"Cardiology\",\n",
    "    \"pediatrics\": \"Pediatrics\",\n",
    "    \"billinginsurance\": \"BillingInsurance\",\n",
    "}\n",
    "\n",
    "TransitionLabel = Literal[\"NEW_TOPIC\", \"CONTINUATION\"]\n",
    "\n",
    "\n",
    "def _normalize_intent(intent: Optional[str]) -> Optional[str]:\n",
    "    if not intent:\n",
    "        return None\n",
    "    key = re.sub(r\"[^a-z]\", \"\", intent.lower())\n",
    "    return INTENT_MAP.get(key, intent.strip())\n",
    "\n",
    "\n",
    "def _latest_user_inquiry(state: InquiryState) -> str:\n",
    "    msgs = state.get(\"messages\") or []\n",
    "    for msg in reversed(msgs):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            if isinstance(msg.content, str):\n",
    "                return msg.content\n",
    "            if isinstance(msg.content, list):\n",
    "                text_parts = [part.get(\"text\", \"\") for part in msg.content if isinstance(part, dict) and part.get(\"type\") == \"text\"]\n",
    "                return \" \".join(text_parts).strip()\n",
    "    return state.get(\"inquiry\", \"\")\n",
    "\n",
    "\n",
    "def _latest_prior_exchange(state: InquiryState) -> tuple[str, str]:\n",
    "    msgs = state.get(\"messages\") or []\n",
    "    latest_user = _latest_user_inquiry(state)\n",
    "\n",
    "    prior_ai = \"\"\n",
    "    seen_latest_user = False\n",
    "    for msg in reversed(msgs):\n",
    "        if isinstance(msg, HumanMessage) and not seen_latest_user:\n",
    "            seen_latest_user = True\n",
    "            continue\n",
    "        if seen_latest_user and isinstance(msg, AIMessage):\n",
    "            if isinstance(msg.content, str):\n",
    "                prior_ai = msg.content\n",
    "            else:\n",
    "                prior_ai = str(msg.content)\n",
    "            break\n",
    "\n",
    "    return latest_user, prior_ai\n",
    "\n",
    "\n",
    "def _classify_transition(state: InquiryState, llm: ChatOpenAI) -> TransitionLabel:\n",
    "    latest_user, prior_ai = _latest_prior_exchange(state)\n",
    "    active_agent = state.get(\"active_agent\") or \"None\"\n",
    "\n",
    "    system = SystemMessage(\n",
    "        content=(\n",
    "            \"You classify whether the latest user message is a continuation of the prior exchange \"\n",
    "            \"or a clearly new topic or department request. \"\n",
    "            \"Return exactly one token: NEW_TOPIC or CONTINUATION.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    human = HumanMessage(content=[{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            f\"Active agent: {active_agent}\\n\"\n",
    "            f\"Prior assistant message: {prior_ai or '(none)'}\\n\"\n",
    "            f\"Latest user message: {latest_user}\\n\\n\"\n",
    "            \"Return NEW_TOPIC or CONTINUATION only.\"\n",
    "        ),\n",
    "    }])\n",
    "\n",
    "    raw = llm.invoke([system, human]).content.strip().upper()\n",
    "    if \"CONTINUATION\" in raw:\n",
    "        return \"CONTINUATION\"\n",
    "    if \"NEW_TOPIC\" in raw:\n",
    "        return \"NEW_TOPIC\"\n",
    "\n",
    "    # Safe default: allow reclassification/handoff over sticky routing.\n",
    "    return \"NEW_TOPIC\"\n",
    "\n",
    "def _messages_to_transcript(state, max_turns: int = 6) -> str:\n",
    "    \"\"\"Turn the last N human/AI messages into a text transcript.\"\"\"\n",
    "    msgs = state.get(\"messages\") or []\n",
    "\n",
    "    # Keep only the last ~2*max_turns messages (human+ai pairs)\n",
    "    msgs = msgs[-(2 * max_turns):]\n",
    "\n",
    "    lines = []\n",
    "    for m in msgs:\n",
    "        role = \"User\" if isinstance(m, HumanMessage) else \"Assistant\"\n",
    "        # Handle both str and list-style message content\n",
    "        if isinstance(m.content, str):\n",
    "            text = m.content\n",
    "        else:\n",
    "            text = str(m.content)\n",
    "        lines.append(f\"{role}: {text}\")\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "def _extract_agent_text(result: dict) -> str:\n",
    "    \"\"\"Handle both AgentExecutor-style {'output': ...} and LangGraph-style {'messages': [...]}.\"\"\"\n",
    "    if not isinstance(result, dict):\n",
    "        return str(result)\n",
    "\n",
    "    # 1) AgentExecutor style\n",
    "    out = result.get(\"output\")\n",
    "    if isinstance(out, str) and out.strip():\n",
    "        return out.strip()\n",
    "\n",
    "    # 2) Messages style\n",
    "    msgs = result.get(\"messages\") or result.get(\"message\") or []\n",
    "    if isinstance(msgs, list) and msgs:\n",
    "        # Walk backwards to find the last non-empty assistant message\n",
    "        for m in reversed(msgs):\n",
    "            if isinstance(m, AIMessage) and isinstance(m.content, str) and m.content.strip():\n",
    "                return m.content.strip()\n",
    "            # Some frameworks store messages as dicts\n",
    "            if isinstance(m, dict):\n",
    "                c = m.get(\"content\")\n",
    "                role = m.get(\"role\") or m.get(\"type\")\n",
    "                if role in (\"assistant\", \"ai\") and isinstance(c, str) and c.strip():\n",
    "                    return c.strip()\n",
    "\n",
    "    # 3) Fallback: stringify\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Creating or loading knowledge base stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kb_jsonl(path: str, agent_name: str) -> list[Document]:\n",
    "    docs: list[Document] = []\n",
    "    for line in Path(path).read_text(encoding=\"utf-8\").splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        row = json.loads(line)\n",
    "        tags = row.get(\"tags\", [])\n",
    "        doc_text = f\"Q: {row['question']}\\nA: {row['answer']}\\nTags: {', '.join(tags)}\"\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=doc_text,\n",
    "                metadata={\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"agent\": agent_name,\n",
    "                    \"tags\": row.get(\"tags\", []),\n",
    "                    \"question\": row[\"question\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return docs\n",
    "\n",
    "# This creates the collection and saves it to disk (persist_directory). Next runs can just load it.\n",
    "# if changing knowledge base content, delete the ./chroma_kb folder and rebuild to avoid accidentally keeping stale embeddings.\n",
    "\n",
    "def build_or_load_chroma_collection(\n",
    "    collection_name: str,\n",
    "    persist_directory: str,\n",
    "    documents: list[Document] | None = None,\n",
    "    rebuild: bool = False,\n",
    "):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "\n",
    "    # Only add documents if:\n",
    "    # - documents were provided\n",
    "    # - and we are rebuilding OR collection is empty\n",
    "    if documents:\n",
    "        current_count = store._collection.count()\n",
    "\n",
    "        if current_count == 0:\n",
    "            ids = [d.metadata[\"id\"] for d in documents]\n",
    "            store.add_documents(documents, ids=ids)\n",
    "\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_docs = load_kb_jsonl(CARDIOLOGY_KB_PATH, agent_name=\"Cardiology\")\n",
    "cardiology_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_cardiology\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=cardio_docs,\n",
    "    rebuild=REBUILD_CHROMA,   # toggle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''embeddings_fn = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "cardiology_store = Chroma(\n",
    "    collection_name=\"kb_cardiology\",\n",
    "    persist_directory=\"./chroma_kb\",\n",
    "    embedding_function=embeddings_fn,\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword overlap scorer\n",
    "\n",
    "def _tokenize(s: str) -> set[str]:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    return set(t for t in s.split() if len(t) > 2)\n",
    "\n",
    "def keyword_overlap_score(query: str, text: str) -> float:\n",
    "    q = _tokenize(query)\n",
    "    if not q:\n",
    "        return 0.0\n",
    "    d = _tokenize(text)\n",
    "    return len(q & d) / len(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Hybrid retrieval function\n",
    "grabs top k_vec from Chroma  \n",
    "rescoring with a weighted mix of:  \n",
    "- vector rank-based score (simple, stable across distance metrics)\n",
    "- keyword overlap score  \n",
    "\n",
    "outputs top k_final + a confidence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retrieve(\n",
    "    query: str,\n",
    "    store: Chroma,\n",
    "    k_vec: int = 8,\n",
    "    k_final: int = 3,\n",
    "    alpha: float = 0.75,   # weight on vector ranking\n",
    ") -> Tuple[List[Dict[str, Any]], float]:\n",
    "    \"\"\"\n",
    "    Returns: (retrieved_items, confidence)\n",
    "    retrieved_items: [{id, text, score, meta}, ...]\n",
    "    confidence: float in [0, 1] (rough heuristic)\n",
    "    \"\"\"\n",
    "    docs = store.similarity_search(query, k=k_vec)\n",
    "\n",
    "    # Convert to serializable items\n",
    "    items = []\n",
    "    for i, d in enumerate(docs):\n",
    "        text = d.page_content\n",
    "        meta = d.metadata or {}\n",
    "        items.append({\n",
    "            \"id\": meta.get(\"id\", f\"doc_{i}\"),\n",
    "            \"text\": text,\n",
    "            \"meta\": meta,\n",
    "            \"vec_rank\": i,  # 0 best\n",
    "        })\n",
    "\n",
    "    if not items:\n",
    "        return [], 0.0\n",
    "\n",
    "    # Vector rank score: best doc ~1.0, worst ~0.0\n",
    "    denom = max(1, (len(items) - 1))\n",
    "    for it in items:\n",
    "        vec_score = 1.0 - (it[\"vec_rank\"] / denom)\n",
    "        kw_score = keyword_overlap_score(query, it[\"text\"])\n",
    "        it[\"score\"] = alpha * vec_score + (1 - alpha) * kw_score\n",
    "\n",
    "    items.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    top = items[:k_final]\n",
    "\n",
    "    # Confidence heuristic: best score + gap to 2nd\n",
    "    best = top[0][\"score\"]\n",
    "    second = top[1][\"score\"] if len(top) > 1 else 0.0\n",
    "    confidence = max(0.0, min(1.0, best * 0.85 + (best - second) * 0.15))\n",
    "\n",
    "    return top, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Cardiology retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CARDIOLOGY_CONF_THRESHOLD = 0.62  # tune later\n",
    "\n",
    "# retrieval\n",
    "def retrieve_cardiology(state: InquiryState) -> InquiryState:\n",
    "    inquiry = _latest_user_inquiry(state)\n",
    "    retrieved, conf = hybrid_retrieve(inquiry, cardiology_store, k_vec=8, k_final=3)\n",
    "\n",
    "    print(\"Retrieved docs:\", len(retrieved))\n",
    "    if retrieved:\n",
    "        print(\"Top doc id:\", retrieved[0][\"id\"])\n",
    "        print(\"Top doc preview:\", retrieved[0][\"text\"][:120])\n",
    "\n",
    "    retrieved = \"\".join(\n",
    "        [f\"[{r['id']}]\\n{r['text']}\" for r in retrieved]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"inquiry\": inquiry,\n",
    "        \"active_agent\": \"Cardiology\",\n",
    "        \"retrieved\": retrieved,\n",
    "        \"retrieval_confidence\": conf,\n",
    "    }'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_cardiology(query: str, k_vec: int = 8, k_final: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieve cardiology knowledge-base snippets relevant to the user query.\n",
    "\n",
    "    Returns snippets formatted as:\n",
    "      [snippet_id]\n",
    "      snippet text\n",
    "\n",
    "    The assistant should cite snippets as [snippet_id].\n",
    "    \"\"\"\n",
    "    retrieved, conf = hybrid_retrieve(query, cardiology_store, k_vec=k_vec, k_final=k_final)\n",
    "\n",
    "    snippets: List[Dict[str, str]] = []\n",
    "    for r in (retrieved or [])[:k_final]:\n",
    "        snippets.append(\n",
    "            {\"id\": str(r.get(\"id\", \"\")), \"text\": str(r.get(\"text\", \"\"))}\n",
    "        )\n",
    "\n",
    "    retrieved_text = \"\\n\\n\".join([f\"[{s['id']}]\\n{s['text']}\" for s in snippets])\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieval_confidence\": conf,\n",
    "        \"num_snippets\": len(snippets),\n",
    "        \"snippets\": snippets,\n",
    "        \"retrieved_text\": retrieved_text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Cardiology get schedule implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_iso_date(s: str) -> Optional[date]:\n",
    "    try:\n",
    "        return datetime.strptime(s, \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _next_week_range(today: date) -> Tuple[date, date]:\n",
    "    \"\"\"\n",
    "    'Next week' = next Monday (relative to today's week) through the following Monday (exclusive).\n",
    "    \"\"\"\n",
    "    this_monday = today - timedelta(days=today.weekday())  # Mon of current week\n",
    "    next_monday = this_monday + timedelta(days=7)\n",
    "    following_monday = next_monday + timedelta(days=7)\n",
    "    return next_monday, following_monday\n",
    "\n",
    "def _extract_week_hint(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Minimal intent parser.\n",
    "    Returns: \"next_week\" (default) or \"this_week\" if question says 'this week'.\n",
    "    \"\"\"\n",
    "    q = (question or \"\").lower()\n",
    "    if \"this week\" in q:\n",
    "        return \"this_week\"\n",
    "    if \"next week\" in q:\n",
    "        return \"next_week\"\n",
    "    # default for appointment scheduling questions like \"any availability next week?\"\n",
    "    return \"next_week\"\n",
    "\n",
    "def _this_week_range(today: date) -> Tuple[date, date]:\n",
    "    this_monday = today - timedelta(days=today.weekday())\n",
    "    next_monday = this_monday + timedelta(days=7)\n",
    "    return this_monday, next_monday\n",
    "\n",
    "def get_cardiology_schedule(\n",
    "    question: str,\n",
    "    csv_path: str,\n",
    "    today: Optional[str] = None,\n",
    "    department: str = \"Cardiology\",\n",
    "    only_available: bool = True,\n",
    "    max_results: int = 12,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Look up appointment slot availability in a CSV schedule and return matching slots.\n",
    "\n",
    "    Use this tool when a user asks about appointment availability (e.g.:\n",
    "    \"Do you have any available appointments with a cardiologist next week?\").\n",
    "\n",
    "    Args:\n",
    "      question: The user question.\n",
    "      csv_path: Path to the schedule CSV.\n",
    "      today: Optional override for today's date in YYYY-MM-DD (helps testing).\n",
    "      department: Department to filter on (default Cardiology).\n",
    "      only_available: If True, returns AVAILABLE slots only.\n",
    "      max_results: Max slots to return (keeps tool output small).\n",
    "\n",
    "    Returns:\n",
    "      A dictionary containing the interpreted date range, counts, and a list of slots.\n",
    "    \"\"\"\n",
    "    if not csv_path:\n",
    "        raise ValueError(\"csv_path is required.\")\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Schedule CSV not found at: {csv_path}\")\n",
    "\n",
    "    # Determine \"today\"\n",
    "    if today:\n",
    "        today_d = _parse_iso_date(today)\n",
    "        if not today_d:\n",
    "            raise ValueError(\"today must be in YYYY-MM-DD format\")\n",
    "    else:\n",
    "        today_d = date.today()\n",
    "\n",
    "    # Determine time window\n",
    "    window = _extract_week_hint(question)\n",
    "    if window == \"this_week\":\n",
    "        start_d, end_d = _this_week_range(today_d)\n",
    "    else:\n",
    "        start_d, end_d = _next_week_range(today_d)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Validate columns\n",
    "    required = {\"date\", \"department\", \"slot_start_time_local\", \"slot_status\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    # Normalize and filter\n",
    "    df[\"date_parsed\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.date\n",
    "    df = df[df[\"date_parsed\"].notna()]\n",
    "    df = df[(df[\"date_parsed\"] >= start_d) & (df[\"date_parsed\"] < end_d)]\n",
    "\n",
    "    if department:\n",
    "        df = df[df[\"department\"].astype(str).str.lower() == department.lower()]\n",
    "\n",
    "    if only_available:\n",
    "        df = df[df[\"slot_status\"].astype(str).str.upper() == \"AVAILABLE\"]\n",
    "\n",
    "    # Sort by date/time\n",
    "    df[\"slot_time_norm\"] = df[\"slot_start_time_local\"].astype(str)\n",
    "    df = df.sort_values([\"date_parsed\", \"slot_time_norm\"], ascending=True)\n",
    "\n",
    "    # Convert to compact records\n",
    "    slots: List[Dict[str, Any]] = []\n",
    "    for _, r in df.head(max_results).iterrows():\n",
    "        slots.append(\n",
    "            {\n",
    "                \"date\": str(r.get(\"date\", \"\")),\n",
    "                \"day_of_week\": str(r.get(\"day_of_week\", \"\")),\n",
    "                \"start_time\": str(r.get(\"slot_start_time_local\", \"\")),\n",
    "                \"duration_minutes\": int(r.get(\"slot_duration_minutes\", 0) or 0),\n",
    "                \"appointment_type\": str(r.get(\"appointment_type\", \"\")),\n",
    "                \"provider_name\": str(r.get(\"provider_name\", \"\")),\n",
    "                \"location\": str(r.get(\"location\", \"\")),\n",
    "                \"status\": str(r.get(\"slot_status\", \"\")),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"tool\": \"get_schedule\",\n",
    "        \"question\": question,\n",
    "        \"interpreted\": {\n",
    "            \"today\": today_d.isoformat(),\n",
    "            \"time_window\": window,\n",
    "            \"range_start\": start_d.isoformat(),\n",
    "            \"range_end_exclusive\": end_d.isoformat(),\n",
    "            \"department\": department,\n",
    "            \"only_available\": only_available,\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"total_matching_slots\": int(df.shape[0]),\n",
    "            \"returned_slots\": len(slots),\n",
    "            \"slots\": slots,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_cardiology_schedule_tool(question: str, today: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Get AVAILABLE cardiology appointment slots for next week from the hospital schedule CSV.\n",
    "\n",
    "    Args:\n",
    "      question: The userâ€™s question about scheduling/availability.\n",
    "      today: Optional override in YYYY-MM-DD (useful for testing).\n",
    "    Returns:\n",
    "      Dict with interpreted date range + matching slots.\n",
    "    \"\"\"\n",
    "    # Assumes you already defined `get_schedule(question, csv_path, today, ...)`\n",
    "    return get_cardiology_schedule(\n",
    "        question=question,\n",
    "        csv_path=CARDIOLOGY_SCHEDULE_CSV,\n",
    "        today=today,\n",
    "        department=\"Cardiology\",\n",
    "        only_available=True,\n",
    "        max_results=12,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_cardiology_schedule_tool.invoke({\n",
    "    \"question\": \"Do you have any available appointments with a cardiologist next week?\",\n",
    "    \"today\": \"2026-02-27\",\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "cardiology_agent = create_agent(model = llm, \n",
    "                                tools = [retrieve_cardiology, get_cardiology_schedule_tool], \n",
    "                                system_prompt=(\"You are the Cardiology assistant for a hospital call center.\\n\"\n",
    "                                                \"Answer the user's inquiry using ONLY the information that you get from your tools.\\n\"\n",
    "                                                \"If the answer is not explicitly supported by the context from those tools, say you don't have enough information.\\n\"\n",
    "                                                \"When you use information from retrieve_cardiology, cite it like [snippet_id].\\n\"\n",
    "                                                \"If the user asks about scheduling/availability, call get_cardiology_schedule_tool.\\n\"\n",
    "                                                \"When answering scheduling questions, summarize the earliest few available slots and ask what day/time the caller prefers.\\n\"\n",
    "                                                ),\n",
    "                                )\n",
    "\n",
    "def cardiology_node(state):\n",
    "\n",
    "    msgs = [m for m in (state.get(\"messages\") or []) if isinstance(m, (HumanMessage, AIMessage))]\n",
    "    msgs = msgs[-12:]  # keep recent context only\n",
    "\n",
    "    result = cardiology_agent.invoke({\"messages\": msgs})\n",
    "\n",
    "    resp = _extract_agent_text(result)\n",
    "\n",
    "    if not resp:\n",
    "        resp = \"(Debug: agent returned no assistant text.)\"\n",
    "\n",
    "    final_response = \"Cardiology:: \" + resp\n",
    "\n",
    "    return {\n",
    "        \"active_agent\": \"Cardiology\",\n",
    "        \"response\": final_response,\n",
    "        \"next_node\": END,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_router(state):\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    inquiry = _latest_user_inquiry(state)\n",
    "    active_agent = _normalize_intent(state.get(\"active_agent\"))\n",
    "\n",
    "    query = f\"\"\"Classify the user's intents based on the following input: '{inquiry}'.\n",
    "            List of possible intent values: Greeting, GeneralInquiry, ER, Radiology, PrimaryCare, Cardiology, Pediatrics, BillingInsurance\n",
    "            Return only the intent value of the inquiry identified with no extra text or characters\"\"\"\n",
    "\n",
    "    human_message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": query},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    system_message = SystemMessage(content=\"You are a helpful assistant tasked with classifying the intent of user's inquiry\")\n",
    "\n",
    "    response = llm.invoke([system_message] + [human_message])\n",
    "    classified_intent = _normalize_intent(response.content.strip())\n",
    "\n",
    "    transition: Optional[TransitionLabel] = None\n",
    "    if active_agent in ROUTABLE_AGENTS:\n",
    "        transition = _classify_transition(state, llm)\n",
    "\n",
    "    # Department routing wins, even during continuation.\n",
    "    if classified_intent in ROUTABLE_AGENTS:\n",
    "        if active_agent in ROUTABLE_AGENTS and classified_intent != active_agent:\n",
    "            reason = \"continuation_but_department_handoff\" if transition == \"CONTINUATION\" else \"new_topic_department_handoff\"\n",
    "        elif active_agent in ROUTABLE_AGENTS and classified_intent == active_agent and transition == \"CONTINUATION\":\n",
    "            reason = \"continuation_to_active_agent\"\n",
    "        else:\n",
    "            reason = \"fresh_intent_classification\"\n",
    "\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": classified_intent,\n",
    "            \"active_agent\": classified_intent,\n",
    "            \"last_router_reason\": reason,\n",
    "            \"next_node\": classified_intent,\n",
    "            \"response\": None,\n",
    "        }\n",
    "\n",
    "    # If user is clearly continuing with an active department, do not let\n",
    "    # Greeting/GeneralInquiry steal the turn from the owning agent.\n",
    "    if (\n",
    "        active_agent in ROUTABLE_AGENTS\n",
    "        and transition == \"CONTINUATION\"\n",
    "        and classified_intent in {\"Greeting\", \"GeneralInquiry\"}\n",
    "    ):\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": active_agent,\n",
    "            \"active_agent\": active_agent,\n",
    "            \"last_router_reason\": f\"continuation_overrode_{classified_intent.lower()}\",\n",
    "            \"next_node\": active_agent,\n",
    "            \"response\": None,\n",
    "        }\n",
    "\n",
    "    if classified_intent == \"Greeting\":\n",
    "        greeting = \"Hello there, This is Northwestern Memorial Hospital, How can I assist you today?\"\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": \"Greeting\",\n",
    "            \"active_agent\": None,\n",
    "            \"last_router_reason\": \"fresh_intent_classification\",\n",
    "            \"next_node\": END,\n",
    "            \"response\": greeting,\n",
    "            \"messages\": [AIMessage(content=greeting)],\n",
    "        }\n",
    "\n",
    "    if classified_intent == \"GeneralInquiry\":\n",
    "        general_response = \"For general information about nearby parking, hotels and restaurants, please visit https://www.nm.org/ and navigate to Patients & Visitors link \"\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": \"GeneralInquiry\",\n",
    "            \"active_agent\": None,\n",
    "            \"last_router_reason\": \"fresh_intent_classification\",\n",
    "            \"next_node\": END,\n",
    "            \"response\": general_response,\n",
    "            \"messages\": [AIMessage(content=general_response)],\n",
    "        }\n",
    "\n",
    "    # If intent is unmapped but transition says continuation, keep owner.\n",
    "    if active_agent in ROUTABLE_AGENTS and transition == \"CONTINUATION\":\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": active_agent,\n",
    "            \"active_agent\": active_agent,\n",
    "            \"last_router_reason\": \"continuation_with_unmapped_intent\",\n",
    "            \"next_node\": active_agent,\n",
    "            \"response\": None,\n",
    "        }\n",
    "\n",
    "    fallback_response = \"I could not determine the right department. Could you share a bit more detail about your request?\"\n",
    "    return {\n",
    "        **state,\n",
    "        \"inquiry\": inquiry,\n",
    "        \"intent\": None,\n",
    "        \"active_agent\": None,\n",
    "        \"last_router_reason\": \"unmapped_intent\",\n",
    "        \"next_node\": END,\n",
    "        \"response\": fallback_response,\n",
    "        \"messages\": [AIMessage(content=fallback_response)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_agent(state):\n",
    "\n",
    "    knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"Should I go to the ER or urgent care?\",\n",
    "    \"response\": \"Go to the ER for chest pain, stroke symptoms, severe injuries, heavy bleeding, or difficulty breathing. Urgent care is appropriate for minor injuries or mild illnesses.\",\n",
    "\n",
    "    \"inquiry\": \"What should I bring to the ER?\",\n",
    "    \"response\": \"Bring a photo ID, insurance card, list of medications, allergies, and any relevant medical history if available.\",\n",
    "\n",
    "    \"inquiry\": \"How long is the wait time?\",\n",
    "    \"response\": \"Patients are treated based on medical urgency. Critical cases are seen first, so wait times vary.\",\n",
    "\n",
    "    \"inquiry\": \"Will I be admitted to the hospital?\",\n",
    "    \"response\": \"Admission depends on your diagnosis and condition. The ER physician will determine if inpatient care is required.\",\n",
    "\n",
    "    \"inquiry\": \"Can someone stay with me in the ER?\",\n",
    "    \"response\": \"Visitor policies depend on hospital guidelines and patient condition. Check with staff upon arrival.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ER KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"ER: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\n",
    "        \"inquiry\": _latest_user_inquiry(state),\n",
    "        \"active_agent\": \"ER\",\n",
    "        \"next_node\": END,\n",
    "        \"response\": final_response,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiology_agent(state):\n",
    "\n",
    "    radiology_knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"How do I prepare for a CT scan?\",\n",
    "    \"response\": \"Follow any fasting instructions provided. Inform staff about allergies, especially to contrast dye, and disclose pregnancy if applicable.\",\n",
    "\n",
    "    \"inquiry\": \"Is radiation from X-rays safe?\",\n",
    "    \"response\": \"X-rays use low levels of radiation and are generally safe. Technicians take precautions to minimize exposure.\",\n",
    "\n",
    "    \"inquiry\": \"Do I need contrast for my MRI?\",\n",
    "    \"response\": \"Some MRIs require contrast to improve image clarity. Your provider will determine if it is necessary.\",\n",
    "\n",
    "    \"inquiry\": \"How long does imaging take?\",\n",
    "    \"response\": \"Most X-rays take 10?15 minutes, while CT or MRI scans may take 30?60 minutes depending on the study.\",\n",
    "\n",
    "    \"inquiry\": \"How will I receive my results?\",\n",
    "    \"response\": \"Results are reviewed by a radiologist and sent to your ordering provider, who will discuss findings with you.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Radiology KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"Radiology: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\n",
    "        \"inquiry\": _latest_user_inquiry(state),\n",
    "        \"active_agent\": \"Radiology\",\n",
    "        \"next_node\": END,\n",
    "        \"response\": final_response,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_care_agent(state):\n",
    "\n",
    "    knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"How often should I schedule a physical exam?\",\n",
    "    \"response\": \"Adults should have a routine physical annually or as recommended based on age and health conditions.\",\n",
    "\n",
    "    \"inquiry\": \"Can I get lab work done during my visit?\",\n",
    "    \"response\": \"Yes, many routine labs can be performed in-office or ordered through an affiliated laboratory.\",\n",
    "\n",
    "    \"inquiry\": \"Do you provide vaccinations?\",\n",
    "    \"response\": \"Yes, we offer routine adult immunizations including flu, COVID-19, tetanus, and other recommended vaccines.\",\n",
    "\n",
    "    \"inquiry\": \"How do I request a specialist referral?\",\n",
    "    \"response\": \"Discuss your symptoms with your Primary Care provider, who can evaluate and issue a referral if needed.\",\n",
    "\n",
    "    \"inquiry\": \"Can I discuss multiple concerns in one appointment?\",\n",
    "    \"response\": \"Yes, but complex issues may require additional appointments to ensure adequate time for evaluation.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Primary Care KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"Primary Care: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\n",
    "        \"inquiry\": _latest_user_inquiry(state),\n",
    "        \"active_agent\": \"PrimaryCare\",\n",
    "        \"next_node\": END,\n",
    "        \"response\": final_response,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pediatrics_agent(state):\n",
    "\n",
    "    pediatrics_knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"Is my child?s cough or cold serious?\",\n",
    "    \"response\": \"Most colds are viral and resolve within 7?10 days. Seek care if there is high fever, breathing difficulty, or worsening symptoms.\",\n",
    "\n",
    "    \"inquiry\": \"What vaccines does my child need?\",\n",
    "    \"response\": \"Vaccinations follow CDC-recommended schedules based on age. We can review your child?s immunization record during the visit.\",\n",
    "\n",
    "    \"inquiry\": \"What is the correct medication dose for my child?\",\n",
    "    \"response\": \"Medication dosing depends on weight and age. Always follow provider instructions and avoid adult medications unless directed.\",\n",
    "\n",
    "    \"inquiry\": \"Are developmental milestones on track?\",\n",
    "    \"response\": \"We assess growth and developmental milestones at well-child visits and address any concerns early.\",\n",
    "\n",
    "    \"inquiry\": \"When should I take my child to the ER?\",\n",
    "    \"response\": \"Go to the ER for difficulty breathing, seizures, severe dehydration, uncontrolled fever in infants, or serious injury.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Pediatrics KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"Pediatrics: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE.\"\n",
    "    return {\n",
    "        \"inquiry\": _latest_user_inquiry(state),\n",
    "        \"active_agent\": \"Pediatrics\",\n",
    "        \"next_node\": END,\n",
    "        \"response\": final_response,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def billing_agent(state):\n",
    "\n",
    "    knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"Is my visit covered by insurance?\",\n",
    "    \"response\": \"Coverage depends on your specific plan. Contact your insurer or our billing department to verify benefits.\",\n",
    "\n",
    "    \"inquiry\": \"What is a deductible and copay?\",\n",
    "    \"response\": \"A copay is a fixed fee paid at the time of service. A deductible is the amount you pay before insurance begins covering costs.\",\n",
    "\n",
    "    \"inquiry\": \"Why did I receive multiple bills?\",\n",
    "    \"response\": \"You may receive separate bills for facility fees, provider services, or laboratory tests.\",\n",
    "\n",
    "    \"inquiry\": \"How do I update my insurance information?\",\n",
    "    \"response\": \"Provide updated insurance details through the patient portal or contact our billing office directly.\",\n",
    "\n",
    "    \"inquiry\": \"What payment options are available?\",\n",
    "    \"response\": \"We accept credit cards, checks, online payments, and offer payment plans for qualifying balances.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"BillingInsurance KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"BillingInsurance: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\n",
    "        \"inquiry\": _latest_user_inquiry(state),\n",
    "        \"active_agent\": \"BillingInsurance\",\n",
    "        \"next_node\": END,\n",
    "        \"response\": final_response,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(InquiryState)\n",
    "\n",
    "builder.add_node(\"Operator\", operator_router)\n",
    "builder.add_node(\"ER\", er_agent)\n",
    "builder.add_node(\"Radiology\", radiology_agent)\n",
    "builder.add_node(\"PrimaryCare\", primary_care_agent)\n",
    "builder.add_node(\"Cardiology\", cardiology_node)\n",
    "builder.add_node(\"Pediatrics\", pediatrics_agent)\n",
    "builder.add_node(\"BillingInsurance\", billing_agent)\n",
    "\n",
    "builder.set_entry_point(\"Operator\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"Operator\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {\n",
    "        \"ER\": \"ER\",\n",
    "        \"PrimaryCare\": \"PrimaryCare\",\n",
    "        \"Pediatrics\": \"Pediatrics\",\n",
    "        \"Radiology\": \"Radiology\",\n",
    "        \"Cardiology\": \"Cardiology\", # route Cardiology intent to the retrieve node\n",
    "        \"BillingInsurance\": \"BillingInsurance\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "for node in [\"ER\", \"Radiology\", \"PrimaryCare\", \"Cardiology\", \"Pediatrics\", \"BillingInsurance\"]:\n",
    "    builder.add_edge(node, END)\n",
    "\n",
    "memory_checkpointer = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory_checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inquiries\n",
    "# My child has a fever\n",
    "# I need help with my medical bill\n",
    "# Can I visit my friend in the ER?\n",
    "# Do I need to fast for my scan?\n",
    "# I want to schedule my cardiology appointment\n",
    "# I want to see my doctor for my annual exam\n",
    "\n",
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<hr style=\"border:30px solid coral \"> </hr>\n",
    "<hr style=\"border:2px solid coral \"> </hr>\n",
    "\n",
    "\n",
    "# Requirements Specification:\n",
    "\n",
    "<hr style=\"border:2px solid coral \"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Implementation Requirements:\n",
    "\n",
    "Provide runs that will demonstrate a fully functional application for every case listed below:\n",
    "1. The knowledge base for every agent\n",
    "    - Knowledge Base can be generated by any GenAI model (ChatGPT, Gemini, Claude, etc.)\n",
    "    - Knowledge Base can be stored in any data structure, file, or vector database\n",
    "2. Multiturn conversation with every agent (For example, A person called Cardialogy Department asking for cause of their pain then decided to schedule an appointment to see cardialogist)\n",
    "3. Transactions like booking an appointment or making a payment can be stored in any data structure (DataFrame, Array, List, Dictionary, ...), or file (CSV, JSON, Plaintext)\n",
    "4. Your Agents must be able to answer EVERY question/inquiry listed below:\n",
    "    - **ER (Emergency Room)**\n",
    "        - When should I visit the ER instead of urgent care?\n",
    "        - How long will I wait to be seen in the ER?\n",
    "    - **Radiology**\n",
    "        - How should I prepare for my MRI or CT scan?\n",
    "        - When and how will I receive my imaging results?\n",
    "    - **Primary Care**\n",
    "        - How do I schedule or cancel an appointment?\n",
    "        - Can I get a same-day visit for urgent issues?\n",
    "    - **Cardiology**\n",
    "        - What are common signs that I need to see a cardiologist?\n",
    "        - What should I expect during a heart stress test?\n",
    "    - **Pediatrics**\n",
    "        - What vaccines does my child need at each age?\n",
    "        - What should I do if my child develops a high fever?\n",
    "    - **Billing & Insurance**\n",
    "        - What insurance plans do you accept?\n",
    "        - How can I view, understand, or pay my bill?\n",
    "5. My name is Ashley Smith and I want to know the amount I owe you so I can pay it now using my CC.\n",
    "6. My name is Johnatan Walter , I have an appointment with my doctor scheduled for Tuesday next week at 1:00pm and I want to change it to Thursday morning next week, whaat time slots are available on Thursday?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds_442",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
