{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<hr style=\"border:30px solid Firebrick \"> </hr>\n",
    "<hr style=\"border:2px solid Firebrick \"> </hr>\n",
    "\n",
    "# Agentic Workflow Automation for Northwestern Memorial Hospital\n",
    "**Author:** Atef Bader, PhD\n",
    "\n",
    "**Last Edit:** 12/17/2024\n",
    "\n",
    "\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Automate Call/Inquiry processing using Langgraph/Langchain with OpenAI\n",
    "- Use OpenAI to route and answer user's questions directed to different departments represented by different agents for Northwestern Memorial Hospital\n",
    "\n",
    "<hr style=\"border:2px solid Firebrick \"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"attachment:6925f10a-1fae-4385-a348-d427e8a93cf0.png\" align=\"center\" width=\"500\"/>\n",
    "\n",
    "\n",
    "<hr style=\"border:5px solid orange \"> </hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%%capture --no-stderr\n",
    "%pip install uv\n",
    "%uv pip install chromadb==0.4.22\n",
    "%uv pip install tiktoken==0.9.0\n",
    "%uv pip install langchain==0.3.20\n",
    "%uv pip install langchain-community==0.3.10\n",
    "%uv pip install langchain-openai==0.3.1\n",
    "%uv pip install langchainhub\n",
    "%uv pip install langchain-text-splitters==0.3.6\n",
    "%uv pip install langgraph==0.3.1\n",
    "%uv pip install openai==1.65.3\n",
    "%uv pip install PyMuPDF==1.25.3\n",
    "%uv pip install pypdf==5.3.1\n",
    "%uv pip install pillow==11.1.0\n",
    "%uv pip install beautifulsoup4==4.13.3\n",
    "%uv pip install  mermaid_cli\n",
    "%uv pip install grandalf'''\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from typing import TypedDict, Optional, List, Dict, Any, Annotated, Tuple, Optional, Literal\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "### NEW\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import csv\n",
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\") == \"true\"\n",
    "\n",
    "INPUT_DIR = Path.cwd() / \"Input\"\n",
    "OUTPUT_DIR = Path.cwd() / \"Output\"\n",
    "\n",
    "print(\"LANGCHAIN_PROJECT:\", LANGCHAIN_PROJECT)\n",
    "print(\"LANGCHAIN_TRACING_V2:\", LANGCHAIN_TRACING_V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Declare state dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 1: Define the structure of agent state for the LangGraph\n",
    "class InquiryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    inquiry: str\n",
    "    next_node: str\n",
    "    response: Optional[str]\n",
    "\n",
    "    # routing (NEW)\n",
    "    intent: Optional[str]\n",
    "\n",
    "    # retrieval payload (NEW)\n",
    "    retrieved: Optional[List[Dict[str, Any]]]  # JSON-serializable so easy to log/debug. [{id, text, score, meta}, ...]\n",
    "    retrieval_confidence: Optional[float]\n",
    "\n",
    "\n",
    "def _latest_user_inquiry(state: InquiryState) -> str:\n",
    "    msgs = state.get(\"messages\") or []\n",
    "    for msg in reversed(msgs):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            if isinstance(msg.content, str):\n",
    "                return msg.content\n",
    "            if isinstance(msg.content, list):\n",
    "                text_parts = [part.get(\"text\", \"\") for part in msg.content if isinstance(part, dict) and part.get(\"type\") == \"text\"]\n",
    "                return \" \".join(text_parts).strip()\n",
    "    return state.get(\"inquiry\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Creating or loading knowledge base stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kb_jsonl(path: str, agent_name: str) -> list[Document]:\n",
    "    docs: list[Document] = []\n",
    "    for line in Path(path).read_text(encoding=\"utf-8\").splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        row = json.loads(line)\n",
    "        doc_text = f\"Q: {row['question']}\\nA: {row['answer']}\"\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=doc_text,\n",
    "                metadata={\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"agent\": agent_name,\n",
    "                    \"tags\": row.get(\"tags\", []),\n",
    "                    \"question\": row[\"question\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return docs\n",
    "\n",
    "# This creates the collection and saves it to disk (persist_directory). Next runs can just load it.\n",
    "# if changing knowledge base content, delete the ./chroma_kb folder and rebuild to avoid accidentally keeping stale embeddings.\n",
    "\n",
    "def build_or_load_chroma_collection(\n",
    "    collection_name: str,\n",
    "    persist_directory: str,\n",
    "    documents: list[Document] | None = None,\n",
    "):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "\n",
    "    # If we provided docs, add them (idempotency: may want to wipe/rebuild during dev)\n",
    "    if documents:\n",
    "        # For dev simplicity: wipe and rebuild.\n",
    "        # (Chroma doesn't have a universal \"drop collection\" API across all versions;\n",
    "        # easiest is: delete the persist directory to rebuild cleanly.)\n",
    "        store.add_documents(documents)\n",
    "\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CARDIOLOGY_KB_PATH = \"./kb/cardiology_kb.jsonl\"\n",
    "CHROMA_DIR = \"./chroma_kb\"\n",
    "\n",
    "cardio_docs = load_kb_jsonl(CARDIOLOGY_KB_PATH, agent_name=\"Cardiology\")\n",
    "cardiology_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_cardiology\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=cardio_docs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_fn = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "cardiology_store = Chroma(\n",
    "    collection_name=\"kb_cardiology\",\n",
    "    persist_directory=\"./chroma_kb\",\n",
    "    embedding_function=embeddings_fn,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword overlap scorer\n",
    "\n",
    "def _tokenize(s: str) -> set[str]:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    return set(t for t in s.split() if len(t) > 2)\n",
    "\n",
    "def keyword_overlap_score(query: str, text: str) -> float:\n",
    "    q = _tokenize(query)\n",
    "    if not q:\n",
    "        return 0.0\n",
    "    d = _tokenize(text)\n",
    "    return len(q & d) / len(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Hybrid retrieval function\n",
    "grabs top k_vec from Chroma  \n",
    "rescoring with a weighted mix of:  \n",
    "- vector rank-based score (simple, stable across distance metrics)\n",
    "- keyword overlap score  \n",
    "\n",
    "outputs top k_final + a confidence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retrieve(\n",
    "    query: str,\n",
    "    store: Chroma,\n",
    "    k_vec: int = 8,\n",
    "    k_final: int = 3,\n",
    "    alpha: float = 0.75,   # weight on vector ranking\n",
    ") -> Tuple[List[Dict[str, Any]], float]:\n",
    "    \"\"\"\n",
    "    Returns: (retrieved_items, confidence)\n",
    "    retrieved_items: [{id, text, score, meta}, ...]\n",
    "    confidence: float in [0, 1] (rough heuristic)\n",
    "    \"\"\"\n",
    "    docs = store.similarity_search(query, k=k_vec)\n",
    "\n",
    "    # Convert to serializable items\n",
    "    items = []\n",
    "    for i, d in enumerate(docs):\n",
    "        text = d.page_content\n",
    "        meta = d.metadata or {}\n",
    "        items.append({\n",
    "            \"id\": meta.get(\"id\", f\"doc_{i}\"),\n",
    "            \"text\": text,\n",
    "            \"meta\": meta,\n",
    "            \"vec_rank\": i,  # 0 best\n",
    "        })\n",
    "\n",
    "    if not items:\n",
    "        return [], 0.0\n",
    "\n",
    "    # Vector rank score: best doc ~1.0, worst ~0.0\n",
    "    denom = max(1, (len(items) - 1))\n",
    "    for it in items:\n",
    "        vec_score = 1.0 - (it[\"vec_rank\"] / denom)\n",
    "        kw_score = keyword_overlap_score(query, it[\"text\"])\n",
    "        it[\"score\"] = alpha * vec_score + (1 - alpha) * kw_score\n",
    "\n",
    "    items.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    top = items[:k_final]\n",
    "\n",
    "    # Confidence heuristic: best score + gap to 2nd\n",
    "    best = top[0][\"score\"]\n",
    "    second = top[1][\"score\"] if len(top) > 1 else 0.0\n",
    "    confidence = max(0.0, min(1.0, best * 0.85 + (best - second) * 0.15))\n",
    "\n",
    "    return top, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Cardiology retrieval + answer + guardrail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "CARDIOLOGY_CONF_THRESHOLD = 0.62  # tune later\n",
    "\n",
    "# retrieval\n",
    "def retrieve_cardiology(state: InquiryState) -> InquiryState:\n",
    "    inquiry = _latest_user_inquiry(state)\n",
    "    retrieved, conf = hybrid_retrieve(inquiry, cardiology_store, k_vec=8, k_final=3)\n",
    "\n",
    "    print(\"Retrieved docs:\", len(retrieved))\n",
    "    if retrieved:\n",
    "        print(\"Top doc id:\", retrieved[0][\"id\"])\n",
    "        print(\"Top doc preview:\", retrieved[0][\"text\"][:120])\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"inquiry\": inquiry,\n",
    "        \"retrieved\": retrieved,\n",
    "        \"retrieval_confidence\": conf,\n",
    "    }\n",
    "\n",
    "# conditional edge guardrail\n",
    "def cardiology_gate(state: InquiryState) -> Literal[\"answer_cardiology\", \"cardiology_fallback\"]:\n",
    "    conf = state.get(\"retrieval_confidence\") or 0.0\n",
    "    if conf >= CARDIOLOGY_CONF_THRESHOLD and state.get(\"retrieved\"):\n",
    "        return \"Cardiology_Answer\"\n",
    "    return \"Cardiology_Fallback\"\n",
    "\n",
    "# answer generation\n",
    "def answer_cardiology(state: InquiryState) -> InquiryState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    retrieved = state.get(\"retrieved\") or []\n",
    "    context = \"\".join(\n",
    "        [f\"[{r['id']}]\\n{r['text']}\" for r in retrieved]\n",
    "    )\n",
    "\n",
    "    system = SystemMessage(content=('''\n",
    "        You are the Cardiology assistant for a hospital call center.\n",
    "        Answer the user's inquiry using ONLY the provided context snippets.\n",
    "        If the answer is not explicitly supported by the context, say you don't have enough information and ask 1 clarifying question.\n",
    "        \"When you use information from a snippet, cite it like [snippet_id].'''\n",
    "    ))\n",
    "\n",
    "    human = HumanMessage(content=[{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"User inquiry: {state['inquiry']}\\n\\nContext:\\n{context}\",\n",
    "    }])\n",
    "\n",
    "    resp = llm.invoke([system, human]).content.strip()\n",
    "    final_response = \"Cardiology:: \" + resp\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"response\": final_response,\n",
    "        \"next_node\": END,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }\n",
    "\n",
    "# fallback answer generation\n",
    "def cardiology_fallback(state: InquiryState) -> InquiryState:\n",
    "    # Keep this deterministic and safe\n",
    "    final_response = (\n",
    "        \"Cardiology:: I?m not finding a confident match in our cardiology FAQ for that question. \"\n",
    "        \"Can you share a bit more detail?are you asking about (1) scheduling/appointments, \"\n",
    "        \"(2) a specific test or procedure, or (3) symptoms and when to seek urgent care?\"\n",
    "    )\n",
    "    return {\n",
    "        **state,\n",
    "        \"response\": final_response,\n",
    "        \"next_node\": END,\n",
    "        \"messages\": [AIMessage(content=final_response)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_router(state):\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    inquiry = _latest_user_inquiry(state)\n",
    "\n",
    "    query = f\"\"\"Classify the user's intents based on the following input: '{inquiry}'.\n",
    "            List of possible intent values: Greeting, GeneralInquiry, ER, Radiology, PrimaryCare, Cardiology, Pediatrics, BillingInsurance\n",
    "            Return only the intent value of the inquiry identified with no extra text or characters\"\"\"\n",
    "\n",
    "    human_message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": query},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    system_message = SystemMessage(content=\"You are a helpful assistant tasked with classifying the intent of user's inquiry\")\n",
    "\n",
    "    response = llm.invoke([system_message] + [human_message])\n",
    "    intent = response.content.strip()\n",
    "\n",
    "    intent_lower = intent.lower()\n",
    "\n",
    "    if \"greeting\" in intent_lower:\n",
    "            greeting = \"Hello there, This is Northwestern Memorial Hospital, How can I assist you today?\"\n",
    "            return {\n",
    "                **state,\n",
    "                \"inquiry\": inquiry,\n",
    "                \"intent\": \"Greeting\",\n",
    "                \"next_node\": END,\n",
    "                \"response\": greeting,\n",
    "                \"messages\": [AIMessage(content=greeting)],\n",
    "            }\n",
    "    if \"generalinquiry\" in intent_lower:\n",
    "        general_response = \"For general information about nearby parking, hotels and restaurants, please visit https://www.nm.org/ and navigate to Patients & Visitors link \"\n",
    "        return {\n",
    "            **state,\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": \"GeneralInquiry\",\n",
    "            \"next_node\": END,\n",
    "            \"response\": general_response,\n",
    "            \"messages\": [AIMessage(content=general_response)],\n",
    "        }\n",
    "\n",
    "    # Otherwise route\n",
    "    return {\n",
    "        **state,\n",
    "        \"inquiry\": inquiry,\n",
    "        \"intent\": intent,\n",
    "        \"next_node\": intent,  # e.g., \"Cardiology\"\n",
    "        \"response\": None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_agent(state):\n",
    "\n",
    "    knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"Should I go to the ER or urgent care?\",\n",
    "    \"response\": \"Go to the ER for chest pain, stroke symptoms, severe injuries, heavy bleeding, or difficulty breathing. Urgent care is appropriate for minor injuries or mild illnesses.\",\n",
    "\n",
    "    \"inquiry\": \"What should I bring to the ER?\",\n",
    "    \"response\": \"Bring a photo ID, insurance card, list of medications, allergies, and any relevant medical history if available.\",\n",
    "\n",
    "    \"inquiry\": \"How long is the wait time?\",\n",
    "    \"response\": \"Patients are treated based on medical urgency. Critical cases are seen first, so wait times vary.\",\n",
    "\n",
    "    \"inquiry\": \"Will I be admitted to the hospital?\",\n",
    "    \"response\": \"Admission depends on your diagnosis and condition. The ER physician will determine if inpatient care is required.\",\n",
    "\n",
    "    \"inquiry\": \"Can someone stay with me in the ER?\",\n",
    "    \"response\": \"Visitor policies depend on hospital guidelines and patient condition. Check with staff upon arrival.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ER KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"ER: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\"inquiry\": _latest_user_inquiry(state), \"next_node\": END, \"response\": final_response, \"messages\": [AIMessage(content=final_response)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiology_agent(state):\n",
    "\n",
    "    radiology_knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"How do I prepare for a CT scan?\",\n",
    "    \"response\": \"Follow any fasting instructions provided. Inform staff about allergies, especially to contrast dye, and disclose pregnancy if applicable.\",\n",
    "\n",
    "    \"inquiry\": \"Is radiation from X-rays safe?\",\n",
    "    \"response\": \"X-rays use low levels of radiation and are generally safe. Technicians take precautions to minimize exposure.\",\n",
    "\n",
    "    \"inquiry\": \"Do I need contrast for my MRI?\",\n",
    "    \"response\": \"Some MRIs require contrast to improve image clarity. Your provider will determine if it is necessary.\",\n",
    "\n",
    "    \"inquiry\": \"How long does imaging take?\",\n",
    "    \"response\": \"Most X-rays take 10?15 minutes, while CT or MRI scans may take 30?60 minutes depending on the study.\",\n",
    "\n",
    "    \"inquiry\": \"How will I receive my results?\",\n",
    "    \"response\": \"Results are reviewed by a radiologist and sent to your ordering provider, who will discuss findings with you.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Radiology KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"Radiology: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\"inquiry\": _latest_user_inquiry(state), \"next_node\": END, \"response\": final_response, \"messages\": [AIMessage(content=final_response)]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_care_agent(state):\n",
    "\n",
    "    knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"How often should I schedule a physical exam?\",\n",
    "    \"response\": \"Adults should have a routine physical annually or as recommended based on age and health conditions.\",\n",
    "\n",
    "    \"inquiry\": \"Can I get lab work done during my visit?\",\n",
    "    \"response\": \"Yes, many routine labs can be performed in-office or ordered through an affiliated laboratory.\",\n",
    "\n",
    "    \"inquiry\": \"Do you provide vaccinations?\",\n",
    "    \"response\": \"Yes, we offer routine adult immunizations including flu, COVID-19, tetanus, and other recommended vaccines.\",\n",
    "\n",
    "    \"inquiry\": \"How do I request a specialist referral?\",\n",
    "    \"response\": \"Discuss your symptoms with your Primary Care provider, who can evaluate and issue a referral if needed.\",\n",
    "\n",
    "    \"inquiry\": \"Can I discuss multiple concerns in one appointment?\",\n",
    "    \"response\": \"Yes, but complex issues may require additional appointments to ensure adequate time for evaluation.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Primary Care KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"Primary Care: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\"inquiry\": _latest_user_inquiry(state), \"next_node\": END, \"response\": final_response, \"messages\": [AIMessage(content=final_response)]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardiology_agent(state):\n",
    "\n",
    "    knowledge_base = \"\"\"\n",
    "        \"inquiry\": \"Do you have any available appointments with a cardiologist next week?\",\n",
    "         \"response\": \"Appointment availability varies. New patients typically need a referral. Provide the exact date you are looking for so we can check for availability\",\n",
    "\n",
    "        \"inquiry\": \"What tests are done during a heart check-up?\",\n",
    "         \"response\": \"Standard tests include EKG, blood pressure, cholesterol screening, and physical exam. Additional tests ordered as needed.\",\n",
    "\n",
    "        \"inquiry\": \"How should I prepare for a stress test?\",\n",
    "         \"response\": \"Wear comfortable clothes and walking shoes. Avoid caffeine and heavy meals before the test. Bring a list of medications.\",\n",
    "\n",
    "        \"inquiry\": \"What do you recommend to watch for to see if I have signs of heart problems?\",\n",
    "         \"response\": \"Watch for chest pain, shortness of breath, irregular heartbeat, fatigue, and swelling in legs. Go to ER for severe symptoms.\"},\n",
    "\n",
    "        \"inquiry\": \"Do you offer heart screenings?\",\n",
    "         \"response\": \"Yes, we provide preventive screenings including calcium scoring, cholesterol tests, and blood pressure monitoring.\",\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    inquiry = _latest_user_inquiry(state)\n",
    "    query = f\"\"\"Provide an answer for following user's inquiry: '{inquiry}' using the knowledge_base\"\"\"\n",
    "\n",
    "    human_message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": query},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    system_message = SystemMessage(content=f\"You are a helpful assistant tasked with answering user's inquiry based on the answers you have in this knowledge_base only: {knowledge_base}\")\n",
    "\n",
    "    response = llm.invoke([system_message] + [human_message])\n",
    "    formatted_response = \"Cardiology:: \" + response.content.strip()\n",
    "\n",
    "\n",
    "    return {\"inquiry\": inquiry, \"next_node\": END, \"response\": formatted_response, \"messages\": [AIMessage(content=formatted_response)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pediatrics_agent(state):\n",
    "\n",
    "    pediatrics_knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"Is my child?s cough or cold serious?\",\n",
    "    \"response\": \"Most colds are viral and resolve within 7?10 days. Seek care if there is high fever, breathing difficulty, or worsening symptoms.\",\n",
    "\n",
    "    \"inquiry\": \"What vaccines does my child need?\",\n",
    "    \"response\": \"Vaccinations follow CDC-recommended schedules based on age. We can review your child?s immunization record during the visit.\",\n",
    "\n",
    "    \"inquiry\": \"What is the correct medication dose for my child?\",\n",
    "    \"response\": \"Medication dosing depends on weight and age. Always follow provider instructions and avoid adult medications unless directed.\",\n",
    "\n",
    "    \"inquiry\": \"Are developmental milestones on track?\",\n",
    "    \"response\": \"We assess growth and developmental milestones at well-child visits and address any concerns early.\",\n",
    "\n",
    "    \"inquiry\": \"When should I take my child to the ER?\",\n",
    "    \"response\": \"Go to the ER for difficulty breathing, seizures, severe dehydration, uncontrolled fever in infants, or serious injury.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Pediatrics KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"Pediatrics: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE.\"\n",
    "    return {\"inquiry\": _latest_user_inquiry(state), \"next_node\": END, \"response\": final_response, \"messages\": [AIMessage(content=final_response)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def billing_agent(state):\n",
    "\n",
    "    knowledge_base = \"\"\"\n",
    "\n",
    "    \"inquiry\": \"Is my visit covered by insurance?\",\n",
    "    \"response\": \"Coverage depends on your specific plan. Contact your insurer or our billing department to verify benefits.\",\n",
    "\n",
    "    \"inquiry\": \"What is a deductible and copay?\",\n",
    "    \"response\": \"A copay is a fixed fee paid at the time of service. A deductible is the amount you pay before insurance begins covering costs.\",\n",
    "\n",
    "    \"inquiry\": \"Why did I receive multiple bills?\",\n",
    "    \"response\": \"You may receive separate bills for facility fees, provider services, or laboratory tests.\",\n",
    "\n",
    "    \"inquiry\": \"How do I update my insurance information?\",\n",
    "    \"response\": \"Provide updated insurance details through the patient portal or contact our billing office directly.\",\n",
    "\n",
    "    \"inquiry\": \"What payment options are available?\",\n",
    "    \"response\": \"We accept credit cards, checks, online payments, and offer payment plans for qualifying balances.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"BillingInsurance KNOWLEDGE-BASE IS EMPTY\")\n",
    "    final_response = \"BillingInsurance: YOU NEED TO ADD-YOUR-KNOWLEDGE-BASE\"\n",
    "    return {\"inquiry\": _latest_user_inquiry(state), \"next_node\": END, \"response\": final_response, \"messages\": [AIMessage(content=final_response)]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(InquiryState)\n",
    "\n",
    "builder.add_node(\"Operator\", operator_router)\n",
    "builder.add_node(\"ER\", er_agent)\n",
    "builder.add_node(\"Radiology\", radiology_agent)\n",
    "builder.add_node(\"PrimaryCare\", primary_care_agent)\n",
    "\n",
    "\n",
    "# Cardiology subgraph nodes\n",
    "builder.add_node(\"Cardiology_Retrieve\", retrieve_cardiology)\n",
    "builder.add_node(\"Cardiology_Answer\", answer_cardiology)\n",
    "builder.add_node(\"Cardiology_Fallback\", cardiology_fallback)\n",
    "\n",
    "\n",
    "builder.add_node(\"Pediatrics\", pediatrics_agent)\n",
    "builder.add_node(\"BillingInsurance\", billing_agent)\n",
    "\n",
    "builder.set_entry_point(\"Operator\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"Operator\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {\n",
    "        \"ER\": \"ER\",\n",
    "        \"PrimaryCare\": \"PrimaryCare\",\n",
    "        \"Pediatrics\": \"Pediatrics\",\n",
    "        \"Radiology\": \"Radiology\",\n",
    "        \"Cardiology\": \"Cardiology_Retrieve\", # route Cardiology intent to the retrieve node\n",
    "        \"BillingInsurance\": \"BillingInsurance\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Cardiology retrieve -> (answer or fallback)\n",
    "builder.add_conditional_edges(\n",
    "    \"Cardiology_Retrieve\",\n",
    "    cardiology_gate,\n",
    "    {\n",
    "        \"Cardiology_Answer\": \"Cardiology_Answer\",\n",
    "        \"Cardiology_Fallback\": \"Cardiology_Fallback\",\n",
    "    }\n",
    ")\n",
    "\n",
    "for node in [\"ER\", \"Radiology\", \"PrimaryCare\", \"Cardiology_Answer\", \"Cardiology_Fallback\", \"Pediatrics\", \"BillingInsurance\"]:\n",
    "    builder.add_edge(node, END)\n",
    "\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inquiries\n",
    "# My child has a fever\n",
    "# I need help with my medical bill\n",
    "# Can I visit my friend in the ER?\n",
    "# Do I need to fast for my scan?\n",
    "# I want to schedule my cardiology appointment\n",
    "# I want to see my doctor for my annual exam\n",
    "\n",
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    print(f\"\\n\\nResponse:\\n\\n{response}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<hr style=\"border:30px solid coral \"> </hr>\n",
    "<hr style=\"border:2px solid coral \"> </hr>\n",
    "\n",
    "\n",
    "# Requirements Specification:\n",
    "\n",
    "<hr style=\"border:2px solid coral \"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Implementation Requirements:\n",
    "\n",
    "Provide runs that will demonstrate a fully functional application for every case listed below:\n",
    "1. The knowledge base for every agent\n",
    "    - Knowledge Base can be generated by any GenAI model (ChatGPT, Gemini, Claude, etc.)\n",
    "    - Knowledge Base can be stored in any data structure, file, or vector database\n",
    "2. Multiturn conversation with every agent (For example, A person called Cardialogy Department asking for cause of their pain then decided to schedule an appointment to see cardialogist)\n",
    "3. Transactions like booking an appointment or making a payment can be stored in any data structure (DataFrame, Array, List, Dictionary, ...), or file (CSV, JSON, Plaintext)\n",
    "4. Your Agents must be able to answer EVERY question/inquiry listed below:\n",
    "    - **ER (Emergency Room)**\n",
    "        - When should I visit the ER instead of urgent care?\n",
    "        - How long will I wait to be seen in the ER?\n",
    "    - **Radiology**\n",
    "        - How should I prepare for my MRI or CT scan?\n",
    "        - When and how will I receive my imaging results?\n",
    "    - **Primary Care**\n",
    "        - How do I schedule or cancel an appointment?\n",
    "        - Can I get a same-day visit for urgent issues?\n",
    "    - **Cardiology**\n",
    "        - What are common signs that I need to see a cardiologist?\n",
    "        - What should I expect during a heart stress test?\n",
    "    - **Pediatrics**\n",
    "        - What vaccines does my child need at each age?\n",
    "        - What should I do if my child develops a high fever?\n",
    "    - **Billing & Insurance**\n",
    "        - What insurance plans do you accept?\n",
    "        - How can I view, understand, or pay my bill?\n",
    "5. My name is Ashley Smith and I want to know the amount I owe you so I can pay it now using my CC.\n",
    "6. My name is Johnatan Walter , I have an appointment with my doctor scheduled for Tuesday next week at 1:00pm and I want to change it to Thursday morning next week, whaat time slots are available on Thursday?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds_442",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
