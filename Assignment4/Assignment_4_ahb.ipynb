{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<hr style=\"border:30px solid Firebrick \"> </hr>\n",
    "<hr style=\"border:2px solid Firebrick \"> </hr>\n",
    "\n",
    "# Agentic Workflow Automation for Northwestern Memorial Hospital\n",
    "**Author:** Atef Bader, PhD\n",
    "\n",
    "**Last Edit:** 12/17/2024\n",
    "\n",
    "\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Automate Call/Inquiry processing using Langgraph/Langchain with OpenAI\n",
    "- Use OpenAI to route and answer user's questions directed to different departments represented by different agents for Northwestern Memorial Hospital\n",
    "\n",
    "<hr style=\"border:2px solid Firebrick \"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"attachment:6925f10a-1fae-4385-a348-d427e8a93cf0.png\" align=\"center\" width=\"500\"/>\n",
    "\n",
    "\n",
    "<hr style=\"border:5px solid orange \"> </hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%%capture --no-stderr\n",
    "%pip install uv\n",
    "%uv pip install chromadb==0.4.22\n",
    "%uv pip install tiktoken==0.9.0\n",
    "%uv pip install langchain==0.3.20\n",
    "%uv pip install langchain-community==0.3.10\n",
    "%uv pip install langchain-openai==0.3.1\n",
    "%uv pip install langchainhub\n",
    "%uv pip install langchain-text-splitters==0.3.6\n",
    "%uv pip install langgraph==0.3.1\n",
    "%uv pip install openai==1.65.3\n",
    "%uv pip install PyMuPDF==1.25.3\n",
    "%uv pip install pypdf==5.3.1\n",
    "%uv pip install pillow==11.1.0\n",
    "%uv pip install beautifulsoup4==4.13.3\n",
    "%uv pip install  mermaid_cli\n",
    "%uv pip install grandalf'''\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from typing import TypedDict, Optional, List, Dict, Any, Annotated, Tuple, Optional, Literal, Callable\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "### NEW\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain.agents import create_agent\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "from __future__ import annotations\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import csv\n",
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\") == \"true\"\n",
    "\n",
    "INPUT_DIR = Path.cwd() / \"Input\"\n",
    "OUTPUT_DIR = Path.cwd() / \"Output\"\n",
    "\n",
    "KB_DIR = Path.cwd() / \"kb\"\n",
    "\n",
    "CARDIOLOGY_SCHEDULE_CSV = KB_DIR / \"cardiology_appointment_slots.csv\"\n",
    "PRIMARY_CARE_RESULTS_CSV = KB_DIR / \"primary_care_test_results.csv\" \n",
    "\n",
    "CARDIOLOGY_KB_PATH = \"./kb/cardiology_kb.jsonl\"\n",
    "BILLING_KB_PATH = \"./kb/billing_kb.jsonl\"\n",
    "ER_AGENT_KB_PATH = \"./kb/er_agent_kb.jsonl\"\n",
    "PEDIATRICS_KB_PATH = \"./kb/pediatrics_kb.jsonl\"\n",
    "PRIMARY_CARE_KB_PATH = \"./kb/primary_care_kb.jsonl\"\n",
    "RADIOLOGY_KB_PATH = \"./kb/radiology_kb.jsonl\"\n",
    "\n",
    "\n",
    "REBUILD_CHROMA = False   # <-- set to False to reuse persisted DB\n",
    "CHROMA_DIR = \"./chroma_kb\"\n",
    "#CHROMA_DIR = \"./chroma_kb_rebuild\" if REBUILD_CHROMA else \"./chroma_kb\"\n",
    "\n",
    "\n",
    "print(\"LANGCHAIN_PROJECT:\", LANGCHAIN_PROJECT)\n",
    "print(\"LANGCHAIN_TRACING_V2:\", LANGCHAIN_TRACING_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Declare state dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 1: Define the structure of agent state for the LangGraph\n",
    "class InquiryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    inquiry: str\n",
    "    next_node: str\n",
    "    response: Optional[str]\n",
    "\n",
    "    # routing\n",
    "    intent: Optional[str]\n",
    "    active_agent: Optional[str]  # which agent currently owns the thread\n",
    "    last_router_reason: Optional[str]\n",
    "\n",
    "    # retrieval payload\n",
    "    retrieved: Optional[List[Dict[str, Any]]]  # JSON-serializable so easy to log/debug. [{id, text, score, meta}, ...]\n",
    "    retrieval_confidence: Optional[float]\n",
    "\n",
    "    # patient identifying info\n",
    "    patient_id: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Functions and structures for handling messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTABLE_AGENTS = {\n",
    "    \"ER\",\n",
    "    \"Radiology\",\n",
    "    \"PrimaryCare\",\n",
    "    \"Cardiology\",\n",
    "    \"Pediatrics\",\n",
    "    \"BillingInsurance\",\n",
    "}\n",
    "\n",
    "INTENT_MAP = {\n",
    "    \"greeting\": \"Greeting\",\n",
    "    \"generalinquiry\": \"GeneralInquiry\",\n",
    "    \"er\": \"ER\",\n",
    "    \"radiology\": \"Radiology\",\n",
    "    \"primarycare\": \"PrimaryCare\",\n",
    "    \"cardiology\": \"Cardiology\",\n",
    "    \"pediatrics\": \"Pediatrics\",\n",
    "    \"billinginsurance\": \"BillingInsurance\",\n",
    "}\n",
    "\n",
    "TransitionLabel = Literal[\"NEW_TOPIC\", \"CONTINUATION\"]\n",
    "\n",
    "\n",
    "def _normalize_intent(intent: Optional[str]) -> Optional[str]:\n",
    "    if not intent:\n",
    "        return None\n",
    "    key = re.sub(r\"[^a-z]\", \"\", intent.lower())\n",
    "    return INTENT_MAP.get(key, intent.strip())\n",
    "\n",
    "\n",
    "def _latest_user_inquiry(state: InquiryState) -> str:\n",
    "    msgs = state.get(\"messages\") or []\n",
    "    for msg in reversed(msgs):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            if isinstance(msg.content, str):\n",
    "                return msg.content\n",
    "            if isinstance(msg.content, list):\n",
    "                text_parts = [part.get(\"text\", \"\") for part in msg.content if isinstance(part, dict) and part.get(\"type\") == \"text\"]\n",
    "                return \" \".join(text_parts).strip()\n",
    "    return state.get(\"inquiry\", \"\")\n",
    "\n",
    "\n",
    "def _latest_prior_exchange(state: InquiryState) -> tuple[str, str]:\n",
    "    msgs = state.get(\"messages\") or []\n",
    "    latest_user = _latest_user_inquiry(state)\n",
    "\n",
    "    prior_ai = \"\"\n",
    "    seen_latest_user = False\n",
    "    for msg in reversed(msgs):\n",
    "        if isinstance(msg, HumanMessage) and not seen_latest_user:\n",
    "            seen_latest_user = True\n",
    "            continue\n",
    "        if seen_latest_user and isinstance(msg, AIMessage):\n",
    "            if isinstance(msg.content, str):\n",
    "                prior_ai = msg.content\n",
    "            else:\n",
    "                prior_ai = str(msg.content)\n",
    "            break\n",
    "\n",
    "    return latest_user, prior_ai\n",
    "\n",
    "\n",
    "def _classify_transition(state: InquiryState, llm: ChatOpenAI) -> TransitionLabel:\n",
    "    latest_user, prior_ai = _latest_prior_exchange(state)\n",
    "    active_agent = state.get(\"active_agent\") or \"None\"\n",
    "\n",
    "    system = SystemMessage(\n",
    "        content=(\n",
    "            \"You classify whether the latest user message is a continuation of the prior exchange \"\n",
    "            \"or a clearly new topic or department request. \"\n",
    "            \"Return exactly one token: NEW_TOPIC or CONTINUATION.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    human = HumanMessage(content=[{\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            f\"Active agent: {active_agent}\\n\"\n",
    "            f\"Prior assistant message: {prior_ai or '(none)'}\\n\"\n",
    "            f\"Latest user message: {latest_user}\\n\\n\"\n",
    "            \"Return NEW_TOPIC or CONTINUATION only.\"\n",
    "        ),\n",
    "    }])\n",
    "\n",
    "    raw = llm.invoke([system, human]).content.strip().upper()\n",
    "    if \"CONTINUATION\" in raw:\n",
    "        return \"CONTINUATION\"\n",
    "    if \"NEW_TOPIC\" in raw:\n",
    "        return \"NEW_TOPIC\"\n",
    "\n",
    "    # Safe default: allow reclassification/handoff over sticky routing.\n",
    "    return \"NEW_TOPIC\"\n",
    "\n",
    "def _extract_agent_text(result: dict) -> str:\n",
    "    \"\"\"Handle both AgentExecutor-style {'output': ...} and LangGraph-style {'messages': [...]}.\"\"\"\n",
    "    if not isinstance(result, dict):\n",
    "        return str(result)\n",
    "\n",
    "    # 1) AgentExecutor style\n",
    "    out = result.get(\"output\")\n",
    "    if isinstance(out, str) and out.strip():\n",
    "        return out.strip()\n",
    "\n",
    "    # 2) Messages style\n",
    "    msgs = result.get(\"messages\") or result.get(\"message\") or []\n",
    "    if isinstance(msgs, list) and msgs:\n",
    "        # Walk backwards to find the last non-empty assistant message\n",
    "        for m in reversed(msgs):\n",
    "            if isinstance(m, AIMessage) and isinstance(m.content, str) and m.content.strip():\n",
    "                return m.content.strip()\n",
    "            # Some frameworks store messages as dicts\n",
    "            if isinstance(m, dict):\n",
    "                c = m.get(\"content\")\n",
    "                role = m.get(\"role\") or m.get(\"type\")\n",
    "                if role in (\"assistant\", \"ai\") and isinstance(c, str) and c.strip():\n",
    "                    return c.strip()\n",
    "\n",
    "    # 3) Fallback: stringify\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Creating or loading knowledge base stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kb_jsonl(path: str, agent_name: str) -> list[Document]:\n",
    "    docs: list[Document] = []\n",
    "    for line in Path(path).read_text(encoding=\"utf-8\").splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        row = json.loads(line)\n",
    "        tags = row.get(\"tags\", [])\n",
    "        doc_text = f\"Q: {row['question']}\\nA: {row['answer']}\\nTags: {', '.join(tags)}\"\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=doc_text,\n",
    "                metadata={\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"agent\": agent_name,\n",
    "                    \"tags\": row.get(\"tags\", []),\n",
    "                    \"question\": row[\"question\"],\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return docs\n",
    "\n",
    "# This creates the collection and saves it to disk (persist_directory). Next runs can just load it.\n",
    "# if changing knowledge base content, delete the ./chroma_kb folder and rebuild to avoid accidentally keeping stale embeddings.\n",
    "\n",
    "def build_or_load_chroma_collection(\n",
    "    collection_name: str,\n",
    "    persist_directory: str,\n",
    "    documents: list[Document] | None = None,\n",
    "    rebuild: bool = False,\n",
    "):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "\n",
    "    # Only add documents if:\n",
    "    # - documents were provided\n",
    "    # - and we are rebuilding OR collection is empty\n",
    "    if documents:\n",
    "        current_count = store._collection.count()\n",
    "\n",
    "        if current_count == 0:\n",
    "            ids = [d.metadata[\"id\"] for d in documents]\n",
    "            store.add_documents(documents, ids=ids)\n",
    "\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardiology\n",
    "cardio_docs = load_kb_jsonl(CARDIOLOGY_KB_PATH, agent_name=\"Cardiology\")\n",
    "cardiology_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_cardiology\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=cardio_docs,\n",
    "    rebuild=REBUILD_CHROMA,\n",
    ")\n",
    "\n",
    "# Billing\n",
    "billing_docs = load_kb_jsonl(BILLING_KB_PATH, agent_name=\"BillingInsurance\")\n",
    "billing_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_billing\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=billing_docs,\n",
    "    rebuild=REBUILD_CHROMA,\n",
    ")\n",
    "\n",
    "# ER\n",
    "er_docs = load_kb_jsonl(ER_AGENT_KB_PATH, agent_name=\"ER\")\n",
    "er_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_er\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=er_docs,\n",
    "    rebuild=REBUILD_CHROMA,\n",
    ")\n",
    "\n",
    "# Pediatrics\n",
    "pediatrics_docs = load_kb_jsonl(PEDIATRICS_KB_PATH, agent_name=\"Pediatrics\")\n",
    "pediatrics_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_pediatrics\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=pediatrics_docs,\n",
    "    rebuild=REBUILD_CHROMA,\n",
    ")\n",
    "\n",
    "# Primary Care\n",
    "primary_care_docs = load_kb_jsonl(PRIMARY_CARE_KB_PATH, agent_name=\"PrimaryCare\")\n",
    "primary_care_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_primary_care\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=primary_care_docs,\n",
    "    rebuild=REBUILD_CHROMA,\n",
    ")\n",
    "\n",
    "# Radiology\n",
    "radiology_docs = load_kb_jsonl(RADIOLOGY_KB_PATH, agent_name=\"Radiology\")\n",
    "radiology_store = build_or_load_chroma_collection(\n",
    "    collection_name=\"kb_radiology\",\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    documents=radiology_docs,\n",
    "    rebuild=REBUILD_CHROMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword overlap scorer\n",
    "\n",
    "def _tokenize(s: str) -> set[str]:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    return set(t for t in s.split() if len(t) > 2)\n",
    "\n",
    "def keyword_overlap_score(query: str, text: str) -> float:\n",
    "    q = _tokenize(query)\n",
    "    if not q:\n",
    "        return 0.0\n",
    "    d = _tokenize(text)\n",
    "    return len(q & d) / len(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Hybrid retrieval function\n",
    "grabs top k_vec from Chroma  \n",
    "rescoring with a weighted mix of:  \n",
    "- vector rank-based score (simple, stable across distance metrics)\n",
    "- keyword overlap score  \n",
    "\n",
    "outputs top k_final + a confidence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retrieve(\n",
    "    query: str,\n",
    "    store: Chroma,\n",
    "    k_vec: int = 8,\n",
    "    k_final: int = 3,\n",
    "    alpha: float = 0.75,   # weight on vector ranking\n",
    ") -> Tuple[List[Dict[str, Any]], float]:\n",
    "    \"\"\"\n",
    "    Returns: (retrieved_items, confidence)\n",
    "    retrieved_items: [{id, text, score, meta}, ...]\n",
    "    confidence: float in [0, 1] (rough heuristic)\n",
    "    \"\"\"\n",
    "    docs = store.similarity_search(query, k=k_vec)\n",
    "\n",
    "    # Convert to serializable items\n",
    "    items = []\n",
    "    for i, d in enumerate(docs):\n",
    "        text = d.page_content\n",
    "        meta = d.metadata or {}\n",
    "        items.append({\n",
    "            \"id\": meta.get(\"id\", f\"doc_{i}\"),\n",
    "            \"text\": text,\n",
    "            \"meta\": meta,\n",
    "            \"vec_rank\": i,  # 0 best\n",
    "        })\n",
    "\n",
    "    if not items:\n",
    "        return [], 0.0\n",
    "\n",
    "    # Vector rank score: best doc ~1.0, worst ~0.0\n",
    "    denom = max(1, (len(items) - 1))\n",
    "    for it in items:\n",
    "        vec_score = 1.0 - (it[\"vec_rank\"] / denom)\n",
    "        kw_score = keyword_overlap_score(query, it[\"text\"])\n",
    "        it[\"score\"] = alpha * vec_score + (1 - alpha) * kw_score\n",
    "\n",
    "    items.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    top = items[:k_final]\n",
    "\n",
    "    # Confidence heuristic: best score + gap to 2nd\n",
    "    best = top[0][\"score\"]\n",
    "    second = top[1][\"score\"] if len(top) > 1 else 0.0\n",
    "    confidence = max(0.0, min(1.0, best * 0.85 + (best - second) * 0.15))\n",
    "\n",
    "    return top, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''@tool\n",
    "def retrieve_cardiology(query: str, k_vec: int = 8, k_final: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieve cardiology knowledge-base snippets relevant to the user query.\n",
    "\n",
    "    Returns snippets formatted as:\n",
    "      [snippet_id]\n",
    "      snippet text\n",
    "\n",
    "    The assistant should cite snippets as [snippet_id].\n",
    "    \"\"\"\n",
    "    retrieved, conf = hybrid_retrieve(query, cardiology_store, k_vec=k_vec, k_final=k_final)\n",
    "\n",
    "    snippets: List[Dict[str, str]] = []\n",
    "    for r in (retrieved or [])[:k_final]:\n",
    "        snippets.append(\n",
    "            {\"id\": str(r.get(\"id\", \"\")), \"text\": str(r.get(\"text\", \"\"))}\n",
    "        )\n",
    "\n",
    "    retrieved_text = \"\\n\\n\".join([f\"[{s['id']}]\\n{s['text']}\" for s in snippets])\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieval_confidence\": conf,\n",
    "        \"num_snippets\": len(snippets),\n",
    "        \"snippets\": snippets,\n",
    "        \"retrieved_text\": retrieved_text,\n",
    "    }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Reusable retriever tool factory\n",
    "# -----------------------------\n",
    "\n",
    "def make_retriever_tool(store, tool_name: str, department_label: str):\n",
    "    \"\"\"\n",
    "    Creates a LangChain tool that retrieves KB snippets from the given Chroma store\n",
    "    using hybrid_retrieve(...) function.\n",
    "\n",
    "    Returns a standardized response dict with:\n",
    "      - query\n",
    "      - retrieval_confidence\n",
    "      - num_snippets\n",
    "      - snippets: [{id, text}, ...]\n",
    "      - retrieved_text: formatted as:\n",
    "            [snippet_id]\n",
    "            snippet text\n",
    "\n",
    "    The assistant should cite snippets as [snippet_id].\n",
    "    \"\"\"\n",
    "\n",
    "    def _retrieve(query: str, k_vec: int = 8, k_final: int = 3) -> Dict[str, Any]:\n",
    "        retrieved, conf = hybrid_retrieve(query, store, k_vec=k_vec, k_final=k_final)\n",
    "\n",
    "        snippets: List[Dict[str, str]] = []\n",
    "        for r in (retrieved or [])[:k_final]:\n",
    "            snippets.append(\n",
    "                {\"id\": str(r.get(\"id\", \"\")), \"text\": str(r.get(\"text\", \"\"))}\n",
    "            )\n",
    "\n",
    "        retrieved_text = \"\\n\\n\".join([f\"[{s['id']}]\\n{s['text']}\" for s in snippets])\n",
    "\n",
    "        return {\n",
    "            \"department\": department_label,\n",
    "            \"query\": query,\n",
    "            \"retrieval_confidence\": conf,\n",
    "            \"num_snippets\": len(snippets),\n",
    "            \"snippets\": snippets,\n",
    "            \"retrieved_text\": retrieved_text,\n",
    "        }\n",
    "\n",
    "    return StructuredTool.from_function(\n",
    "        func=_retrieve,\n",
    "        name=tool_name,\n",
    "        description=(\n",
    "            f\"Retrieve {department_label} knowledge-base snippets relevant to the user query. \"\n",
    "            \"Returns snippets formatted as [snippet_id] followed by snippet text. \"\n",
    "            \"The assistant should cite snippets as [snippet_id].\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Department-specific tools\n",
    "# -----------------------------\n",
    "retrieve_cardiology = make_retriever_tool(\n",
    "    store=cardiology_store,\n",
    "    tool_name=\"retrieve_cardiology\",\n",
    "    department_label=\"Cardiology\",\n",
    ")\n",
    "\n",
    "retrieve_billing = make_retriever_tool(\n",
    "    store=billing_store,\n",
    "    tool_name=\"retrieve_billing\",\n",
    "    department_label=\"Billing\",\n",
    ")\n",
    "\n",
    "retrieve_er = make_retriever_tool(\n",
    "    store=er_store,\n",
    "    tool_name=\"retrieve_er\",\n",
    "    department_label=\"Emergency Room\",\n",
    ")\n",
    "\n",
    "retrieve_pediatrics = make_retriever_tool(\n",
    "    store=pediatrics_store,\n",
    "    tool_name=\"retrieve_pediatrics\",\n",
    "    department_label=\"Pediatrics\",\n",
    ")\n",
    "\n",
    "retrieve_primary_care = make_retriever_tool(\n",
    "    store=primary_care_store,\n",
    "    tool_name=\"retrieve_primary_care\",\n",
    "    department_label=\"Primary Care\",\n",
    ")\n",
    "\n",
    "retrieve_radiology = make_retriever_tool(\n",
    "    store=radiology_store,\n",
    "    tool_name=\"retrieve_radiology\",\n",
    "    department_label=\"Radiology\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Cardiology get schedule implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_iso_date(s: str) -> Optional[date]:\n",
    "    try:\n",
    "        return datetime.strptime(s, \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _next_week_range(today: date) -> Tuple[date, date]:\n",
    "    \"\"\"\n",
    "    'Next week' = next Monday (relative to today's week) through the following Monday (exclusive).\n",
    "    \"\"\"\n",
    "    this_monday = today - timedelta(days=today.weekday())  # Mon of current week\n",
    "    next_monday = this_monday + timedelta(days=7)\n",
    "    following_monday = next_monday + timedelta(days=7)\n",
    "    return next_monday, following_monday\n",
    "\n",
    "def _extract_week_hint(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Minimal intent parser.\n",
    "    Returns: \"next_week\" (default) or \"this_week\" if question says 'this week'.\n",
    "    \"\"\"\n",
    "    q = (question or \"\").lower()\n",
    "    if \"this week\" in q:\n",
    "        return \"this_week\"\n",
    "    if \"next week\" in q:\n",
    "        return \"next_week\"\n",
    "    # default for appointment scheduling questions like \"any availability next week?\"\n",
    "    return \"next_week\"\n",
    "\n",
    "def _this_week_range(today: date) -> Tuple[date, date]:\n",
    "    this_monday = today - timedelta(days=today.weekday())\n",
    "    next_monday = this_monday + timedelta(days=7)\n",
    "    return this_monday, next_monday\n",
    "\n",
    "def get_cardiology_schedule(\n",
    "    question: str,\n",
    "    csv_path: str,\n",
    "    today: Optional[str] = None,\n",
    "    department: str = \"Cardiology\",\n",
    "    only_available: bool = True,\n",
    "    max_results: int = 12,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Look up appointment slot availability in a CSV schedule and return matching slots.\n",
    "\n",
    "    Use this tool when a user asks about appointment availability (e.g.:\n",
    "    \"Do you have any available appointments with a cardiologist next week?\").\n",
    "\n",
    "    Args:\n",
    "      question: The user question.\n",
    "      csv_path: Path to the schedule CSV.\n",
    "      today: Optional override for today's date in YYYY-MM-DD (helps testing).\n",
    "      department: Department to filter on (default Cardiology).\n",
    "      only_available: If True, returns AVAILABLE slots only.\n",
    "      max_results: Max slots to return (keeps tool output small).\n",
    "\n",
    "    Returns:\n",
    "      A dictionary containing the interpreted date range, counts, and a list of slots.\n",
    "    \"\"\"\n",
    "    if not csv_path:\n",
    "        raise ValueError(\"csv_path is required.\")\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Schedule CSV not found at: {csv_path}\")\n",
    "\n",
    "    # Determine \"today\"\n",
    "    if today:\n",
    "        today_d = _parse_iso_date(today)\n",
    "        if not today_d:\n",
    "            raise ValueError(\"today must be in YYYY-MM-DD format\")\n",
    "    else:\n",
    "        today_d = date.today()\n",
    "\n",
    "    # Determine time window\n",
    "    window = _extract_week_hint(question)\n",
    "    if window == \"this_week\":\n",
    "        start_d, end_d = _this_week_range(today_d)\n",
    "    else:\n",
    "        start_d, end_d = _next_week_range(today_d)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Validate columns\n",
    "    required = {\"date\", \"department\", \"slot_start_time_local\", \"slot_status\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    # Normalize and filter\n",
    "    df[\"date_parsed\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.date\n",
    "    df = df[df[\"date_parsed\"].notna()]\n",
    "    df = df[(df[\"date_parsed\"] >= start_d) & (df[\"date_parsed\"] < end_d)]\n",
    "\n",
    "    if department:\n",
    "        df = df[df[\"department\"].astype(str).str.lower() == department.lower()]\n",
    "\n",
    "    if only_available:\n",
    "        df = df[df[\"slot_status\"].astype(str).str.upper() == \"AVAILABLE\"]\n",
    "\n",
    "    # Sort by date/time\n",
    "    df[\"slot_time_norm\"] = df[\"slot_start_time_local\"].astype(str)\n",
    "    df = df.sort_values([\"date_parsed\", \"slot_time_norm\"], ascending=True)\n",
    "\n",
    "    # Convert to compact records\n",
    "    slots: List[Dict[str, Any]] = []\n",
    "    for _, r in df.head(max_results).iterrows():\n",
    "        slots.append(\n",
    "            {\n",
    "                \"date\": str(r.get(\"date\", \"\")),\n",
    "                \"day_of_week\": str(r.get(\"day_of_week\", \"\")),\n",
    "                \"start_time\": str(r.get(\"slot_start_time_local\", \"\")),\n",
    "                \"duration_minutes\": int(r.get(\"slot_duration_minutes\", 0) or 0),\n",
    "                \"appointment_type\": str(r.get(\"appointment_type\", \"\")),\n",
    "                \"provider_name\": str(r.get(\"provider_name\", \"\")),\n",
    "                \"location\": str(r.get(\"location\", \"\")),\n",
    "                \"status\": str(r.get(\"slot_status\", \"\")),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"tool\": \"get_schedule\",\n",
    "        \"question\": question,\n",
    "        \"interpreted\": {\n",
    "            \"today\": today_d.isoformat(),\n",
    "            \"time_window\": window,\n",
    "            \"range_start\": start_d.isoformat(),\n",
    "            \"range_end_exclusive\": end_d.isoformat(),\n",
    "            \"department\": department,\n",
    "            \"only_available\": only_available,\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"total_matching_slots\": int(df.shape[0]),\n",
    "            \"returned_slots\": len(slots),\n",
    "            \"slots\": slots,\n",
    "        },\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def get_cardiology_schedule_tool(question: str, today: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Get AVAILABLE cardiology appointment slots for next week from the hospital schedule CSV.\n",
    "\n",
    "    Args:\n",
    "      question: The user’s question about scheduling/availability.\n",
    "      today: Optional override in YYYY-MM-DD (useful for testing).\n",
    "    Returns:\n",
    "      Dict with interpreted date range + matching slots.\n",
    "    \"\"\"\n",
    "    # Assumes you already defined `get_schedule(question, csv_path, today, ...)`\n",
    "    return get_cardiology_schedule(\n",
    "        question=question,\n",
    "        csv_path=CARDIOLOGY_SCHEDULE_CSV,\n",
    "        today=today,\n",
    "        department=\"Cardiology\",\n",
    "        only_available=True,\n",
    "        max_results=12,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Test review status tool implementation for primary care agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta, date\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "def _parse_dt(s: str) -> Optional[datetime]:\n",
    "    if not s or not isinstance(s, str):\n",
    "        return None\n",
    "    for fmt in (\"%Y-%m-%d %H:%M\", \"%Y-%m-%dT%H:%M:%S\", \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            # If just a date, treat as midnight local\n",
    "            dt = datetime.strptime(s, fmt)\n",
    "            return dt\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def _extract_recency_days(question: str, default_days: int = 14) -> int:\n",
    "    \"\"\"\n",
    "    Minimal intent parser for 'recent' / 'last X days' / 'last week' / 'latest'.\n",
    "    Returns a day window to search back from \"now\".\n",
    "    \"\"\"\n",
    "    q = (question or \"\").lower()\n",
    "\n",
    "    if \"today\" in q:\n",
    "        return 1\n",
    "    if \"yesterday\" in q:\n",
    "        return 2\n",
    "    if \"last week\" in q:\n",
    "        return 7\n",
    "    if \"past week\" in q:\n",
    "        return 7\n",
    "    if \"recent\" in q:\n",
    "        return default_days\n",
    "    if \"latest\" in q or \"most recent\" in q:\n",
    "        return default_days\n",
    "\n",
    "    # naive parse for \"last 30 days\"\n",
    "    import re\n",
    "    m = re.search(r\"last\\s+(\\d+)\\s+day\", q)\n",
    "    if m:\n",
    "        try:\n",
    "            return max(1, int(m.group(1)))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return default_days\n",
    "\n",
    "\n",
    "def get_primary_care_test_review_status(\n",
    "    question: str,\n",
    "    csv_path: str,\n",
    "    patient_id: str,\n",
    "    now: Optional[str] = None,\n",
    "    department: str = \"Primary Care\",\n",
    "    lookback_days_default: int = 14,\n",
    "    max_results: int = 5,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Look up whether a patient's recent test results have been reviewed by their PCP.\n",
    "\n",
    "    Use this tool when a user asks things like:\n",
    "      - \"Has my recent test result been reviewed by my primary care doctor?\"\n",
    "      - \"Did my PCP look at my labs yet?\"\n",
    "      - \"Any update on my bloodwork?\"\n",
    "\n",
    "    Args:\n",
    "      question: user question (used for recency hints).\n",
    "      csv_path: path to the test results status CSV.\n",
    "      patient_id: identifier (MRN / patient_id).\n",
    "      now: optional override (YYYY-MM-DD or YYYY-MM-DD HH:MM).\n",
    "      department: filter department (default Primary Care).\n",
    "      lookback_days_default: default window for 'recent/latest'.\n",
    "      max_results: cap returned rows.\n",
    "\n",
    "    Returns:\n",
    "      Dict with interpreted window + latest results + review info.\n",
    "    \"\"\"\n",
    "    if not csv_path:\n",
    "        raise ValueError(\"csv_path is required.\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Test results CSV not found at: {csv_path}\")\n",
    "    if not patient_id:\n",
    "        raise ValueError(\"patient_id is required.\")\n",
    "\n",
    "    # Determine \"now\"\n",
    "    now_dt = _parse_dt(now) if now else datetime.now()\n",
    "    if not now_dt:\n",
    "        raise ValueError(\"now must be in YYYY-MM-DD or YYYY-MM-DD HH:MM format\")\n",
    "\n",
    "    lookback_days = _extract_recency_days(question, default_days=lookback_days_default)\n",
    "    start_dt = now_dt - timedelta(days=lookback_days)\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Validate required columns\n",
    "    required = {\n",
    "        \"patient_id\",\n",
    "        \"department\",\n",
    "        \"test_name\",\n",
    "        \"resulted_datetime_local\",\n",
    "        \"review_status\",\n",
    "    }\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"CSV missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    # Normalize types\n",
    "    df[\"patient_id_norm\"] = df[\"patient_id\"].astype(str).str.strip()\n",
    "    df[\"dept_norm\"] = df[\"department\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "    df[\"resulted_dt\"] = pd.to_datetime(df[\"resulted_datetime_local\"], errors=\"coerce\")\n",
    "    df = df[df[\"resulted_dt\"].notna()]\n",
    "\n",
    "    # Filter by patient + department + time window\n",
    "    df = df[df[\"patient_id_norm\"] == str(patient_id).strip()]\n",
    "    if department:\n",
    "        df = df[df[\"dept_norm\"] == department.lower()]\n",
    "\n",
    "    df = df[(df[\"resulted_dt\"] >= start_dt) & (df[\"resulted_dt\"] <= now_dt)]\n",
    "\n",
    "    # Most recent first\n",
    "    df = df.sort_values([\"resulted_dt\"], ascending=False)\n",
    "\n",
    "    # Optional columns (if present)\n",
    "    has_reviewed_dt = \"reviewed_datetime_local\" in df.columns\n",
    "    has_reviewed_by = \"reviewed_by\" in df.columns\n",
    "    has_released = \"released_to_patient\" in df.columns\n",
    "    has_result_status = \"result_status\" in df.columns\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    for _, r in df.head(max_results).iterrows():\n",
    "        item = {\n",
    "            \"test_name\": str(r.get(\"test_name\", \"\")),\n",
    "            \"resulted_datetime_local\": str(r.get(\"resulted_datetime_local\", \"\")),\n",
    "            \"review_status\": str(r.get(\"review_status\", \"\")),\n",
    "        }\n",
    "        if has_result_status:\n",
    "            item[\"result_status\"] = str(r.get(\"result_status\", \"\"))\n",
    "        if has_reviewed_dt:\n",
    "            item[\"reviewed_datetime_local\"] = str(r.get(\"reviewed_datetime_local\", \"\")) if pd.notna(r.get(\"reviewed_datetime_local\", \"\")) else \"\"\n",
    "        if has_reviewed_by:\n",
    "            item[\"reviewed_by\"] = str(r.get(\"reviewed_by\", \"\")) if pd.notna(r.get(\"reviewed_by\", \"\")) else \"\"\n",
    "        if has_released:\n",
    "            item[\"released_to_patient\"] = str(r.get(\"released_to_patient\", \"\"))\n",
    "        results.append(item)\n",
    "\n",
    "    # Summarize “latest” row if exists\n",
    "    latest = results[0] if results else None\n",
    "\n",
    "    return {\n",
    "        \"tool\": \"get_test_review_status\",\n",
    "        \"question\": question,\n",
    "        \"interpreted\": {\n",
    "            \"patient_id\": str(patient_id).strip(),\n",
    "            \"department\": department,\n",
    "            \"now\": now_dt.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "            \"lookback_days\": lookback_days,\n",
    "            \"range_start\": start_dt.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "            \"range_end\": now_dt.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"total_matching_results\": int(df.shape[0]),\n",
    "            \"returned_results\": len(results),\n",
    "            \"latest_result\": latest,\n",
    "            \"recent_results\": results,\n",
    "        },\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def get_primary_care_test_review_status_tool(question: str, patient_id: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Look up review status for a patient's recent Primary Care test results.\n",
    "\n",
    "    If patient_id is missing, returns error.code == MISSING_PATIENT_ID.\n",
    "    \"\"\"\n",
    "    if not patient_id or not str(patient_id).strip():\n",
    "        return {\n",
    "            \"tool\": \"get_test_review_status\",\n",
    "            \"error\": {\n",
    "                \"code\": \"MISSING_PATIENT_ID\",\n",
    "                \"message\": \"patient_id is required to look up test result review status.\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return get_primary_care_test_review_status(\n",
    "        question=question,\n",
    "        csv_path=PRIMARY_CARE_RESULTS_CSV,\n",
    "        patient_id=str(patient_id).strip(),\n",
    "        department=\"Primary Care\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Agents and their nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "BASE_DEPT_PROMPT = (\n",
    "    \"You are the {dept} assistant for a hospital call center.\\n\"\n",
    "    \"Answer the user's inquiry using ONLY the information that you get from your tools.\\n\"\n",
    "    \"If the answer is not explicitly supported by the context from those tools, say you don't have enough information.\\n\"\n",
    "    \"When you use information from {retrieve_tool_name}, cite it like [snippet_id].\\n\"\n",
    ")\n",
    "\n",
    "SCHED_PROMPT_ADDON = (\n",
    "    \"If the user asks about scheduling/availability, call {schedule_tool_name}.\\n\"\n",
    "    \"When answering scheduling questions, summarize the earliest few available slots and ask what day/time the caller prefers.\\n\"\n",
    ")\n",
    "\n",
    "TEST_RESULTS_PROMPT_ADDON = (\n",
    "    \"If the user asks whether a test/lab result has been reviewed (or asks for test result status), \"\n",
    "    \"you MUST call {test_results_tool_name}.\\n\"\n",
    "    \"This requires a patient_id.\\n\"\n",
    "    \"If patient_id is not provided in the current conversation context/state, ask the user for their patient ID \"\n",
    "    \"and DO NOT call the tool until it is provided.\\n\"\n",
    "    \"Do not guess patient_id.\\n\"\n",
    ")\n",
    "\n",
    "TOOL_ERROR_HANDLING_ADDON = (\n",
    "    \"If any tool returns an 'error' object, do NOT fabricate an answer.\\n\"\n",
    "    \"If error.code is 'MISSING_PATIENT_ID', ask the user for their patient ID.\\n\"\n",
    ")\n",
    "\n",
    "def make_department_agent(\n",
    "    *,\n",
    "    dept: str,\n",
    "    retrieve_tool,\n",
    "    retrieve_tool_name: str,\n",
    "    schedule_tool=None,\n",
    "    schedule_tool_name: str | None = None,\n",
    "    extra_tools: list | None = None,\n",
    "    prompt_addons: list[str] | None = None,\n",
    "\n",
    "):\n",
    "    tools = [retrieve_tool]\n",
    "    if schedule_tool:\n",
    "        tools.append(schedule_tool)\n",
    "    if extra_tools:\n",
    "        tools.extend(extra_tools)\n",
    "\n",
    "    system_prompt = BASE_DEPT_PROMPT.format(\n",
    "        dept=dept,\n",
    "        retrieve_tool_name=retrieve_tool_name,\n",
    "    )\n",
    "\n",
    "    # Include global error behavior\n",
    "    system_prompt += TOOL_ERROR_HANDLING_ADDON\n",
    "\n",
    "    if schedule_tool and schedule_tool_name:\n",
    "        system_prompt += SCHED_PROMPT_ADDON.format(schedule_tool_name=schedule_tool_name)\n",
    "\n",
    "    if prompt_addons:\n",
    "        system_prompt += \"\\n\".join(prompt_addons) + \"\\n\"\n",
    "\n",
    "    return create_agent(\n",
    "        model=llm,\n",
    "        tools=tools,\n",
    "        system_prompt=system_prompt,\n",
    "    )\n",
    "\n",
    "def make_department_node(*, agent, dept_label: str, max_history: int = 12, passthrough_keys: list[str] | None = None):\n",
    "    \"\"\"\n",
    "    Returns a LangGraph node function that:\n",
    "      - pulls recent Human/AI messages from state\n",
    "      - invokes the department agent\n",
    "      - prefixes response with '<Dept>:: '\n",
    "      - returns message update in the standardized way\n",
    "    \"\"\"\n",
    "\n",
    "    passthrough_keys = passthrough_keys or [\"patient_id\"]  # safe default\n",
    "\n",
    "    def _node(state):\n",
    "        msgs = [m for m in (state.get(\"messages\") or []) if isinstance(m, (HumanMessage, AIMessage))]\n",
    "        msgs = msgs[-max_history:]  # keep recent context only\n",
    "\n",
    "        agent_input = {\"messages\": msgs}\n",
    "\n",
    "        # pass-through optional fields if they exist\n",
    "        for k in passthrough_keys:\n",
    "            if k in state and state.get(k) not in (None, \"\"):\n",
    "                agent_input[k] = state.get(k)        \n",
    "\n",
    "        result = agent.invoke(agent_input)\n",
    "        resp = _extract_agent_text(result) or \"(Debug: agent returned no assistant text.)\"\n",
    "\n",
    "        final_response = f\"{dept_label}:: {resp}\"\n",
    "\n",
    "        return {\n",
    "            \"active_agent\": dept_label,\n",
    "            \"response\": final_response,\n",
    "            \"next_node\": END,\n",
    "            \"messages\": [AIMessage(content=final_response)],\n",
    "        }\n",
    "\n",
    "    return _node\n",
    "\n",
    "cardiology_agent = make_department_agent(\n",
    "    dept=\"Cardiology\",\n",
    "    retrieve_tool=retrieve_cardiology,\n",
    "    retrieve_tool_name=\"retrieve_cardiology\",\n",
    "    schedule_tool=get_cardiology_schedule_tool,\n",
    "    schedule_tool_name=\"get_cardiology_schedule_tool\",\n",
    ")\n",
    "\n",
    "cardiology_node = make_department_node(\n",
    "    agent=cardiology_agent,\n",
    "    dept_label=\"Cardiology\",\n",
    ")\n",
    "\n",
    "radiology_agent = make_department_agent(\n",
    "    dept=\"Radiology\",\n",
    "    retrieve_tool=retrieve_radiology,\n",
    "    retrieve_tool_name=\"retrieve_radiology\",\n",
    "    # schedule tool optional; include if you have one\n",
    ")\n",
    "\n",
    "radiology_node = make_department_node(\n",
    "    agent=radiology_agent,\n",
    "    dept_label=\"Radiology\",\n",
    ")\n",
    "\n",
    "primary_care_agent = make_department_agent(\n",
    "    dept=\"Primary Care\",\n",
    "    retrieve_tool=retrieve_primary_care,\n",
    "    retrieve_tool_name=\"retrieve_primary_care\",\n",
    "    extra_tools=[get_primary_care_test_review_status_tool],\n",
    "    prompt_addons=[\n",
    "        TEST_RESULTS_PROMPT_ADDON.format(test_results_tool_name=\"get_primary_care_test_review_status_tool\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "primary_care_node = make_department_node(\n",
    "    agent=primary_care_agent,\n",
    "    dept_label=\"PrimaryCare\",\n",
    "    passthrough_keys=[\"patient_id\"], \n",
    ")\n",
    "\n",
    "pediatrics_agent = make_department_agent(\n",
    "    dept=\"Pediatrics\",\n",
    "    retrieve_tool=retrieve_pediatrics,\n",
    "    retrieve_tool_name=\"retrieve_pediatrics\",\n",
    ")\n",
    "\n",
    "pediatrics_node = make_department_node(\n",
    "    agent=pediatrics_agent,\n",
    "    dept_label=\"Pediatrics\",\n",
    ")\n",
    "\n",
    "er_agent = make_department_agent(\n",
    "    dept=\"Emergency Room\",\n",
    "    retrieve_tool=retrieve_er,\n",
    "    retrieve_tool_name=\"retrieve_er\",\n",
    ")\n",
    "\n",
    "er_node = make_department_node(\n",
    "    agent=er_agent,\n",
    "    dept_label=\"ER\",  # label can be shorter if you want\n",
    ")\n",
    "\n",
    "billing_agent = make_department_agent(\n",
    "    dept=\"Billing\",\n",
    "    retrieve_tool=retrieve_billing,\n",
    "    retrieve_tool_name=\"retrieve_billing\",\n",
    ")\n",
    "\n",
    "billing_node = make_department_node(\n",
    "    agent=billing_agent,\n",
    "    dept_label=\"Billing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_router(state):\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    inquiry = _latest_user_inquiry(state)\n",
    "    active_agent = _normalize_intent(state.get(\"active_agent\"))\n",
    "\n",
    "    query = f\"\"\"Classify the user's intents based on the following input: '{inquiry}'.\n",
    "            List of possible intent values: Greeting, GeneralInquiry, ER, Radiology, PrimaryCare, Cardiology, Pediatrics, BillingInsurance\n",
    "            Return only the intent value of the inquiry identified with no extra text or characters\"\"\"\n",
    "\n",
    "    human_message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": query},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    system_message = SystemMessage(content=\"You are a helpful assistant tasked with classifying the intent of user's inquiry\")\n",
    "\n",
    "    response = llm.invoke([system_message] + [human_message])\n",
    "    classified_intent = _normalize_intent(response.content.strip())\n",
    "\n",
    "    transition: Optional[TransitionLabel] = None\n",
    "    if active_agent in ROUTABLE_AGENTS:\n",
    "        transition = _classify_transition(state, llm)\n",
    "\n",
    "    # Department routing wins, even during continuation.\n",
    "    if classified_intent in ROUTABLE_AGENTS:\n",
    "        if active_agent in ROUTABLE_AGENTS and classified_intent != active_agent:\n",
    "            reason = \"continuation_but_department_handoff\" if transition == \"CONTINUATION\" else \"new_topic_department_handoff\"\n",
    "        elif active_agent in ROUTABLE_AGENTS and classified_intent == active_agent and transition == \"CONTINUATION\":\n",
    "            reason = \"continuation_to_active_agent\"\n",
    "        else:\n",
    "            reason = \"fresh_intent_classification\"\n",
    "\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": classified_intent,\n",
    "            \"active_agent\": classified_intent,\n",
    "            \"last_router_reason\": reason,\n",
    "            \"next_node\": classified_intent,\n",
    "            \"response\": None,\n",
    "        }\n",
    "\n",
    "    # If user is clearly continuing with an active department, do not let\n",
    "    # Greeting/GeneralInquiry steal the turn from the owning agent.\n",
    "    if (\n",
    "        active_agent in ROUTABLE_AGENTS\n",
    "        and transition == \"CONTINUATION\"\n",
    "        and classified_intent in {\"Greeting\", \"GeneralInquiry\"}\n",
    "    ):\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": active_agent,\n",
    "            \"active_agent\": active_agent,\n",
    "            \"last_router_reason\": f\"continuation_overrode_{classified_intent.lower()}\",\n",
    "            \"next_node\": active_agent,\n",
    "            \"response\": None,\n",
    "        }\n",
    "\n",
    "    if classified_intent == \"Greeting\":\n",
    "        greeting = \"Hello there, This is Northwestern Memorial Hospital, How can I assist you today?\"\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": \"Greeting\",\n",
    "            \"active_agent\": None,\n",
    "            \"last_router_reason\": \"fresh_intent_classification\",\n",
    "            \"next_node\": END,\n",
    "            \"response\": greeting,\n",
    "            \"messages\": [AIMessage(content=greeting)],\n",
    "        }\n",
    "\n",
    "    if classified_intent == \"GeneralInquiry\":\n",
    "        general_response = \"For general information about nearby parking, hotels and restaurants, please visit https://www.nm.org/ and navigate to Patients & Visitors link \"\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": \"GeneralInquiry\",\n",
    "            \"active_agent\": None,\n",
    "            \"last_router_reason\": \"fresh_intent_classification\",\n",
    "            \"next_node\": END,\n",
    "            \"response\": general_response,\n",
    "            \"messages\": [AIMessage(content=general_response)],\n",
    "        }\n",
    "\n",
    "    # If intent is unmapped but transition says continuation, keep owner.\n",
    "    if active_agent in ROUTABLE_AGENTS and transition == \"CONTINUATION\":\n",
    "        return {\n",
    "            \"inquiry\": inquiry,\n",
    "            \"intent\": active_agent,\n",
    "            \"active_agent\": active_agent,\n",
    "            \"last_router_reason\": \"continuation_with_unmapped_intent\",\n",
    "            \"next_node\": active_agent,\n",
    "            \"response\": None,\n",
    "        }\n",
    "\n",
    "    fallback_response = \"I could not determine the right department. Could you share a bit more detail about your request?\"\n",
    "    return {\n",
    "        **state,\n",
    "        \"inquiry\": inquiry,\n",
    "        \"intent\": None,\n",
    "        \"active_agent\": None,\n",
    "        \"last_router_reason\": \"unmapped_intent\",\n",
    "        \"next_node\": END,\n",
    "        \"response\": fallback_response,\n",
    "        \"messages\": [AIMessage(content=fallback_response)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(InquiryState)\n",
    "\n",
    "builder.add_node(\"Operator\", operator_router)\n",
    "builder.add_node(\"ER\", er_node)\n",
    "builder.add_node(\"Radiology\", radiology_node)\n",
    "builder.add_node(\"PrimaryCare\", primary_care_node)\n",
    "builder.add_node(\"Cardiology\", cardiology_node)\n",
    "builder.add_node(\"Pediatrics\", pediatrics_node)\n",
    "builder.add_node(\"BillingInsurance\", billing_node)\n",
    "\n",
    "builder.set_entry_point(\"Operator\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"Operator\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {\n",
    "        \"ER\": \"ER\",\n",
    "        \"PrimaryCare\": \"PrimaryCare\",\n",
    "        \"Pediatrics\": \"Pediatrics\",\n",
    "        \"Radiology\": \"Radiology\",\n",
    "        \"Cardiology\": \"Cardiology\", \n",
    "        \"BillingInsurance\": \"BillingInsurance\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "for node in [\"ER\", \"Radiology\", \"PrimaryCare\", \"Cardiology\", \"Pediatrics\", \"BillingInsurance\"]:\n",
    "    builder.add_edge(node, END)\n",
    "\n",
    "memory_checkpointer = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory_checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "<hr style=\"border:30px solid coral \"> </hr>\n",
    "<hr style=\"border:2px solid coral \"> </hr>\n",
    "\n",
    "\n",
    "# Requirement 7\n",
    "\n",
    "<hr style=\"border:2px solid coral \"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    " Provide 6 runs that will demonstrate a fully functional application where the Operator AI Agent can route the message successfully to the target\n",
    "department AI Agent who will respond to the inquiry received for every scenario listed below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### How can I tell if my child has RSV (Respiratory Syncytial Virus)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### Can I visit my friend in the ER, and are there any restrictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "#### How should I prepare for a CT scan, and are there any dietary restrictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### I want to check if my recent test result has been reviewed by my primary care physician yet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### Do you have any available appointments with a cardiologist next week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### Can you help me understand my recent medical bill and whether my insurance covered the costs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = input(\"Thread ID (use same ID to continue a conversation): \").strip() or \"default-thread\"\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in {\"q\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = graph.invoke({\"messages\": [HumanMessage(content=user_input)]}, config=config)\n",
    "\n",
    "    assistant_message = next(\n",
    "        (m for m in reversed(result.get(\"messages\", [])) if isinstance(m, AIMessage)),\n",
    "        None,\n",
    "    )\n",
    "    response = assistant_message.content if assistant_message else result.get(\"response\", \"No Response Returned\")\n",
    "    active_agent = result.get(\"active_agent\")\n",
    "    last_router_reason = result.get(\"last_router_reason\")\n",
    "    print(\n",
    "        f\"\\nUser: {user_input}\\n\"\n",
    "        f\"Assistant: {response}\\n\"\n",
    "        f\"state['active_agent']: {active_agent}\\n\"\n",
    "        f\"state['last_router_reason']: {last_router_reason}\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds_442",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
